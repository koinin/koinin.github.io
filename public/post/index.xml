<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on logn 2 - koinin</title>
    <link>https://koinin.github.io/post/</link>
    <description>Recent content in Articles on logn 2 - koinin</description>
    <generator>Hugo</generator>
    <language>zh</language>
    <lastBuildDate>Mon, 19 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://koinin.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>记录第一台主机</title>
      <link>https://koinin.github.io/post/2025/05/19/%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%8F%B0%E4%B8%BB%E6%9C%BA/</link>
      <pubDate>Mon, 19 May 2025 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2025/05/19/%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E5%8F%B0%E4%B8%BB%E6%9C%BA/</guid>
      <description>&lt;p&gt;人生苦短，为欢几何，终于折腾到了第一台主机，虽然买的是整机，但是过程并不顺利。&#xA;配置如下：&#xA;r5 5600x&#xA;msi b450m bazooka plus&#xA;1080&#xA;不知名16g 3000 *2&lt;/p&gt;&#xA;&lt;p&gt;期间遇到了很多问题，卡cpu灯，bios进不去，还叫了上门维修，也总结了一些解决的小问题。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;关于debug灯，最初以为白色和红色会有区别，结果没有&lt;/li&gt;&#xA;&lt;li&gt;关于debug cpu灯亮，实际上很多并非cpu问题，我这内存条不知道什么原因，只能锁2400使用，算了，将就吧，后面再换8g*2&lt;/li&gt;&#xA;&lt;li&gt;am4 cpu一定要预热，不然很容易连根拔起&lt;/li&gt;&#xA;&lt;li&gt;cpu很容易针脚歪，需要注意&lt;/li&gt;&#xA;&lt;li&gt;操作断电&lt;/li&gt;&#xA;&lt;li&gt;阅读主板说明书&lt;/li&gt;&#xA;&lt;li&gt;更新bios, 重置bios。&lt;/li&gt;&#xA;&lt;li&gt;音频问题，这个还没结果，只能通过usb声卡把耳麦连出来解决&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Rl</title>
      <link>https://koinin.github.io/post/2025/04/30/rl/</link>
      <pubDate>Wed, 30 Apr 2025 19:00:15 +0800</pubDate>
      <guid>https://koinin.github.io/post/2025/04/30/rl/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class QNetwork(nn.Module):&#xA;  def __init__(self, env):&#xA;    super(QNetwork, self).__init__()&#xA;    # Get observation space dimensions (expected to be 8: 4 for state, 2 for pos_ee, 2 for goal)&#xA;    self.obs_dim = env.observation_space.shape[0]&#xA;&#xA;    # Define a discrete action space&#xA;    # Let&#39;s create a grid of torque values for each joint&#xA;    # For example, for each joint: [-0.1, -0.05, 0, 0.05, 0.1]&#xA;    # This gives us 5*5=25 possible action combinations for 2 joints&#xA;    self.torque_values = [-0.5, -0.25, 0, 0.25, 0.5]&#xA;    self.num_discrete_actions = len(self.torque_values) ** 2&#xA;&#xA;    # Create action mapping dictionary for converting discrete to continuous&#xA;    self.action_mapping = {}&#xA;    idx = 0&#xA;    for t1 in self.torque_values:&#xA;        for t2 in self.torque_values:&#xA;            self.action_mapping[idx] = np.array([t1, t2])&#xA;            idx += 1&#xA;&#xA;    # Neural network architecture&#xA;    # Input layer: observation dimension&#xA;    # Hidden layers: Two layers with 128 and 64 units&#xA;    # Output layer: Number of discrete actions&#xA;    self.fc1 = nn.Linear(self.obs_dim, 128)&#xA;    self.fc2 = nn.Linear(128, 64)&#xA;    self.fc3 = nn.Linear(64, 32)&#xA;    self.fc4 = nn.Linear(32, self.num_discrete_actions)&#xA;    # 这样的层级架构可以避免128，128，128的过拟合问题，出现损失，reward降低不下去，很有可能就是过拟合了&#xA;&#xA;  def forward(self, x, device):&#xA;    # Convert numpy array to tensor if necessary&#xA;    if isinstance(x, np.ndarray):&#xA;        x = torch.FloatTensor(x)&#xA;&#xA;    # Move input tensor to specified device&#xA;    x = x.to(device)&#xA;&#xA;    # Forward pass through the network&#xA;    x = F.relu(self.fc1(x))&#xA;    x = F.relu(self.fc2(x))&#xA;    x = F.relu(self.fc3(x))  &#xA;    x = self.fc4(x)          &#xA;&#xA;    return x&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from stable_baselines3.ppo import PPO&#xA;import os&#xA;import time&#xA;from stable_baselines3.common.utils import set_random_seed&#xA;&#xA;&#xA;# Default parameters&#xA;timesteps = 500000&#xA;nenv = 8  # number of parallel environments. This can speed up training when you have good CPUs&#xA;seed = 8&#xA;batch_size = 2048&#xA;&#xA;# Generate path of the directory to save the checkpoint&#xA;timestr = time.strftime(&amp;quot;%Y-%m-%d_%H-%M-%S&amp;quot;)&#xA;save_dir = os.path.join(&#39;ppo_models&#39;, timestr)&#xA;&#xA;# Set random seed&#xA;set_random_seed(seed)&#xA;&#xA;# Create arm&#xA;arm = make_arm()&#xA;&#xA;# Create parallel envs&#xA;vec_env = make_vec_env(arm=arm, nenv=nenv, seed=seed)&#xA;&#xA;# ------ IMPLEMENT YOUR TRAINING CODE HERE ------------&#xA;&#xA;# Create the PPO model&#xA;model = PPO(&#xA;    policy=&#39;MlpPolicy&#39;,&#xA;    env=vec_env,&#xA;    batch_size=batch_size,&#xA;    seed=seed,&#xA;    verbose=1,&#xA;    n_epochs=40,         # 每次更新的训练轮数&#xA;    # 邪招，10 -&amp;gt; 40 极大的增加了reward&#xA;    learning_rate=3e-4,  # 学习率&#xA;    gamma=0.99,          # 折扣因子&#xA;    gae_lambda=0.95,     # GAE lambda&#xA;    clip_range=0.2,      # 策略裁剪范围&#xA;)&#xA;&#xA;&#xA;# Train the model&#xA;model.learn(total_timesteps=timesteps)&#xA;&#xA;# Ensure the save directory exists&#xA;os.makedirs(save_dir, exist_ok=True)&#xA;&#xA;# Save the trained model&#xA;model.save(os.path.join(save_dir, &#39;ppo_network&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Raging_loop游玩体验</title>
      <link>https://koinin.github.io/post/2025/03/29/raging_loop%E6%B8%B8%E7%8E%A9%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Sat, 29 Mar 2025 23:55:37 +0800</pubDate>
      <guid>https://koinin.github.io/post/2025/03/29/raging_loop%E6%B8%B8%E7%8E%A9%E4%BD%93%E9%AA%8C/</guid>
      <description>&lt;h1 id=&#34;raging-loop游玩体验&#34;&gt;Raging loop游玩体验&lt;/h1&gt;&#xA;&lt;p&gt;一周目是在一年前玩的了，当时模模糊糊，现在二周目终于弄清楚了时间线。&lt;/p&gt;&#xA;&lt;p&gt;最早日本土著是蜘蛛神，然后随着古代日本人的殖民被取代了，之后地方出现了一个大神，大神对村庄里面的人不满，就用野物来骚扰村庄，之后村庄里的人投票出了三个人柱（夫妻加个孩子），也就是后面的狼神，狼神保佑村庄，村庄供奉狼神，后来上城和下城起矛盾，下城假扮黄泉人去上城屠杀，上城为了抑制下城，就搞了个人狼来取代狼神，并把狼神打作黄泉，供奉了新的神，其中包含土著信仰的蜘蛛，蜘蛛有个能力就是下蛋，通过吸血之类的方式下单，当然也可以帮人消灾，这个能力随着蜘蛛家的家主遗传。&lt;/p&gt;&#xA;&lt;p&gt;上城还一直害怕下城人,就维持了搞狼人杀的传统,而下城的人基本都被蜘蛛下蛋了，这一代蜘蛛家主布了一个局，想让从城里回来的千枝实帮他杀掉所有下了蛋的人，蜘蛛大神就可以复苏。&lt;/p&gt;&#xA;&lt;p&gt;结果千枝实太菜了，几千个轮回都做不到，蜘蛛家主就搞了个阳明进来，不过阳明的前女友刚好是个技术人员，帮他维持了记忆，阳明这个老六，嘴里一句实话没有，阻止了蜘蛛大神复苏,也可以说是咩子阻止了.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Docker Cuda</title>
      <link>https://koinin.github.io/post/2025/03/19/docker-cuda/</link>
      <pubDate>Wed, 19 Mar 2025 13:24:47 +0800</pubDate>
      <guid>https://koinin.github.io/post/2025/03/19/docker-cuda/</guid>
      <description>&lt;p&gt;没想到这么久以后又遇到了cuda的问题，我再次记录一下我的理解&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export CUDA_VISIBLE_DEVICES=0,1&#xA;CUDA_VISIBLE_DEVICES=0,1 python test.py&#xA;pip install -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple some-package&#xA;&#xA;python -c &amp;quot;import torch; print(torch.__version__)&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h1 id=&#34;宿主机cuda&#34;&gt;宿主机cuda&lt;/h1&gt;&#xA;&lt;p&gt;首先你的宿主机的cuda结构应该是 cuda-driver -&amp;gt; cuda toolkit -&amp;gt; pytorch-cuda&lt;/p&gt;&#xA;&lt;p&gt;第一层&lt;/p&gt;&#xA;&lt;p&gt;一般服务器是装好了的&lt;/p&gt;&#xA;&lt;p&gt;第二层&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;Distribution=Ubuntu&amp;amp;target_version=22.04&amp;amp;target_type=runfile_local&#34;&gt;CUDA Toolkit 11.8 Downloads | NVIDIA Developer&lt;/a&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;nvcc -V&#xA;# 一般来说安装在/usr/local/下&#xA;# 可以搜索一下，然后把目标加入环境变量&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;第三层&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;docker-cuda&#34;&gt;Docker-cuda&lt;/h1&gt;&#xA;&lt;p&gt;起因是想解决centos编译库太老旧的问题，把一些编译环境放在docker里面&lt;/p&gt;&#xA;&lt;p&gt;编译这个flash_attn要编译好久好久&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo docker run -it -d \&#xA;  --gpus all \&#xA;  --name my_cuda \&#xA;  --network host \&#xA;  -v /home/sunyatao_B:/root/sunyatao_B \&#xA;  --shm-size=1g \&#xA;  nvidia/cuda:11.8.0-runtime-ubuntu22.04 bash&#xA;  &#xA;sudo docker exec -it my_cuda bash&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Note</title>
      <link>https://koinin.github.io/post/2025/03/02/note/</link>
      <pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2025/03/02/note/</guid>
      <description>&lt;p&gt;[toc]&lt;/p&gt;&#xA;&lt;h1 id=&#34;todo&#34;&gt;TODO&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250409013909918.png&#34; alt=&#34;image-20250409013909918&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;StyleGAN&lt;/li&gt;&#xA;&lt;li&gt;蛋白质图片分类&lt;/li&gt;&#xA;&lt;li&gt;强化学习MAPPO，betaPPO,随机策略&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;gan&#34;&gt;GAN&lt;/h2&gt;&#xA;&lt;p&gt;首先对于一个基本的GAN网络，少不了G和D&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Generator(nn.Module):&#xA;        def __init__(self, latent_dim, num_channels, features_g=64):&#xA;            super(Generator, self).__init__()&#xA;            self.latent_dim = latent_dim&#xA;            self.num_channels = num_channels&#xA;            self.features_g = features_g&#xA;&#xA;# 有几个参数，首先是是latent_dim， 也就是z_dim，G要做的就是不断对这个z_dim上上取样，以生成一个图片&#xA;# features_g反应了G的容量&#xA;            self.main = nn.Sequential(&#xA;                # 输入是 Z 向量 (latent_dim)，输出是 (features_g * 16) x 4 x 4 的特征图&#xA;                nn.ConvTranspose2d(latent_dim, features_g * 16, 4, 1, 0, bias=False),&#xA;                nn.BatchNorm2d(features_g * 16),&#xA;                nn.ReLU(True),&#xA;&#xA;                # (features_g * 16) x 4 x 4 -&amp;gt; (features_g * 8) x 8 x 8&#xA;                nn.ConvTranspose2d(features_g * 16, features_g * 8, 4, 2, 1, bias=False),&#xA;                nn.BatchNorm2d(features_g * 8),&#xA;                nn.ReLU(True),&#xA;&#xA;               ...&#xA;&#xA;                # (features_g / 8) x 512 x 512 -&amp;gt; (num_channels) x 1024 x 1024&#xA;                nn.ConvTranspose2d(features_g // 8, num_channels, 4, 2, 1, bias=False),&#xA;                nn.Tanh() # 或者 nn.Sigmoid()，取决于你的图像数据范围&#xA;            )&#xA;&#xA;        def forward(self, input):&#xA;            # 将输入的 noise 向量 reshape 成 (batch_size, latent_dim, 1, 1)&#xA;            input = input.unsqueeze(-1).unsqueeze(-1)&#xA;            return self.main(input)&#xA;&#xA;class Discriminator(nn.Module):&#xA;        def __init__(self, num_channels, features_d=64):&#xA;            super(Discriminator, self).__init__()&#xA;            self.num_channels = num_channels&#xA;            self.features_d = features_d&#xA;&#xA;            self.main = nn.Sequential(&#xA;                # 输入是 (num_channels) x 1024 x 1024&#xA;                nn.Conv2d(num_channels, features_d // 8, 4, 2, 1, bias=False),&#xA;                nn.LeakyReLU(0.2, inplace=True),&#xA;&#xA;               ...&#xA;&#xA;                # (features_d * 16) x 4 x 4 -&amp;gt; 1 x 1 x 1&#xA;                nn.Conv2d(features_d * 16, 1, 4, 1, 0, bias=False),&#xA;                nn.Sigmoid()&#xA;            )&#xA;&#xA;        def forward(self, input):&#xA;            return self.main(input)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;stylegan2-ada-pytorch&#34;&gt;Stylegan2-ada-pytorch&lt;/h3&gt;&#xA;&lt;p&gt;遇到一个问题，训练了很久也没法降低fid&lt;/p&gt;</description>
    </item>
    <item>
      <title>KAN</title>
      <link>https://koinin.github.io/post/2025/02/24/kan/</link>
      <pubDate>Mon, 24 Feb 2025 16:40:12 +0800</pubDate>
      <guid>https://koinin.github.io/post/2025/02/24/kan/</guid>
      <description>&lt;h2 id=&#34;梯度提升决策树&#34;&gt;梯度提升决策树&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;cite: &lt;a href=&#34;https://www.showmeai.tech/article-detail/193&#34;&gt;图解机器学习 | GBDT模型详解&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;boosting-and-bagging&#34;&gt;Boosting and Bagging&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://img-blog.csdnimg.cn/img_convert/1b9e5f7f3f733bb0f6335829235e7a74.png&#34; alt=&#34;GBDT模型详解; GBDT算法; Boosting核心思想;&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;gbdt&#34;&gt;GBDT&lt;/h3&gt;&#xA;&lt;p&gt;使用残差来迭代下一步的计算&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;初始化回归树&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;$$&#xA;f_1{x} = \arg\min_{c}\sum_{n=1}^{n}L(y_{i},x)&#xA;$$&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;迭代，从第二棵树开始不断计算每一棵树的训练目标， 也就是前面结果的残差&lt;/li&gt;&#xA;&lt;li&gt;对于当前第m棵子树而言，我们需要遍历它的可行的切分点以及阈值，找到最优的预测值c对应的参数，使得尽可能逼近残差，我们来写出这段公式&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;$$&#xA;r_{mi} = -\left[ \frac{\partial L(y_i, f(x_i))}{\partial f(x_i)} \right]_{f(x) = f_{m-1}(x)}&#xA;\\&#xA;c_{mj} = \arg\min_{c} \sum_{x_i \in R_{mj}} L(y_i, f_{m-1}(x_i) + c)&#xA;$$&lt;p&gt;这种Boost思想是否能应用到代理模型呢&lt;/p&gt;&#xA;&lt;h3 id=&#34;xgboost&#34;&gt;XGBOOST&lt;/h3&gt;&#xA;&lt;p&gt;要实现模型复杂度和损失的最小，&lt;/p&gt;&#xA;$$\omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^{T} w_j^2 $$&lt;h3 id=&#34;lightgbm&#34;&gt;LightGBM&lt;/h3&gt;&#xA;&lt;p&gt;和xgboost类似，小样本容易过拟合&lt;/p&gt;&#xA;&lt;p&gt;现在二者没什么本质性差别，lgbm快一点点&lt;/p&gt;&#xA;&lt;h1 id=&#34;kan&#34;&gt;KAN&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/2404.19756&#34;&gt;http://arxiv.org/abs/2404.19756&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;&#xA;&lt;p&gt;受Kolmogorov-Arnold表示定理的启发，我们提出了KolmogorovArnold网络（KANs），作为多层感知机（MLPs）的有前景替代方案。MLPs在节点（“神经元”）上有固定的激活函数，而KANs在边（“权重”）上有可学习的激活函数。KANs完全没有线性权重——每个权重参数都被一个参数化为样条的单变量函数所取代。我们展示了这一看似简单的改变使KANs在准确性和可解释性方面优于MLPs，尤其是在小规模的AI与科学任务中。在准确性方面，较小的KANs在函数拟合任务中可以达到与较大MLPs相当或更好的准确性。理论和实验证明，KANs的神经扩展规律比MLPs更快。在可解释性方面，KANs可以直观地可视化，并能轻松与人类用户互动。通过数学和物理领域的两个例子，KANs被证明是有用的“合作者”，帮助科学家（重新）发现数学和物理定律。总之，KANs是MLPs的有前景替代方案，为进一步改进今天依赖MLPs的深度学习模型提供了机会。&lt;/p&gt;&#xA;&lt;h2 id=&#34;kan-vs-mlp&#34;&gt;KAN vs MLP&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250224164711186.png&#34; alt=&#34;image-20250224164711186&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;ka表示定理&#34;&gt;KA表示定理&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250224193943429.png&#34; alt=&#34;image-20250224193943429&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;对于多元函数而言，可以近似化多个一元函数的和，而这个最后的加法操作才是真正的多元函数&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250225010748745.png&#34; alt=&#34;image-20250225010748745&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是KAN的核心思想，以矩阵形式写的把x，作为$\phi_{\text{in}}$之前的输入，$\phi_{\text{in}}$在作为$\phi{\text{out}}$的输入&lt;/p&gt;</description>
    </item>
    <item>
      <title>State Space</title>
      <link>https://koinin.github.io/post/2025/02/24/state-space/</link>
      <pubDate>Mon, 24 Feb 2025 15:23:23 +0800</pubDate>
      <guid>https://koinin.github.io/post/2025/02/24/state-space/</guid>
      <description>&lt;h2 id=&#34;状态空间方程&#34;&gt;状态空间方程&lt;/h2&gt;&#xA;&lt;h2 id=&#34;状态变量&#34;&gt;状态变量&lt;/h2&gt;&#xA;&lt;p&gt;非线性系统转换为线性系统&lt;/p&gt;&#xA;&lt;p&gt;静态系统和动态系统的区别，对于选择状态变量&lt;/p&gt;&#xA;&lt;h2 id=&#34;转移函数&#34;&gt;转移函数&lt;/h2&gt;&#xA;&lt;p&gt;转移函数矩阵&#xA;&lt;/p&gt;&#xA;$$&#xA;(sI - A)^{-1}D&#xA;$$$$&#xA;\dot{\vec{x}} =  A\vec{x} + B\vec{u}\\ &#xA;sX(s) = A X(s) + BU(s)\\&#xA;\vec{y} = C\vec{x} + D\vec{u}\\&#xA;\frac{Y(s)}{X(s)}&#xA;$$&lt;h2 id=&#34;卡尔曼滤波算法&#34;&gt;卡尔曼滤波算法&lt;/h2&gt;&#xA;&lt;p&gt;线性状态估计&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://www.kalmanfilter.net/img/OneD/Update.png&#34; alt=&#34;State Update Illustration&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250224160553459.png&#34; alt=&#34;image-20250224160553459&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;heading&#34;&gt;&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Git_443_record</title>
      <link>https://koinin.github.io/post/2025/01/17/git_443_record/</link>
      <pubDate>Fri, 17 Jan 2025 13:02:02 +0800</pubDate>
      <guid>https://koinin.github.io/post/2025/01/17/git_443_record/</guid>
      <description>&lt;h1 id=&#34;记录一次clash-tun模式下git失灵push-pill&#34;&gt;记录一次clash Tun模式下git失灵（push pill）&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;参考https://ganzhixiong.com/p/b792e008/&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;也就是在clash内核在tun模式下出于安全问题禁用了22端口，所以&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Connection closed by x.x.x.x port 22&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 测试22端口&#xA;ssh -T git@ssh.github.com&#xA;# 测试443端口&#xA;ssh -vT -p 443 git@ssh.github.com&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;修改.ssh/config就可以解决了&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;Host github.com&#xA;    Hostname ssh.github.com&#xA;    Port 443&#xA;    User git&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>PINN</title>
      <link>https://koinin.github.io/post/2024/12/17/pinn/</link>
      <pubDate>Tue, 17 Dec 2024 17:19:58 +0800</pubDate>
      <guid>https://koinin.github.io/post/2024/12/17/pinn/</guid>
      <description>&lt;h1 id=&#34;pinnphysics-informed-neural-networks-a-deep-learning-framework-for-solving-forward-and-inverse-problems-involving-nonlinear-partial-differential-equations&#34;&gt;PINN:Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations&lt;/h1&gt;&#xA;&lt;h2 id=&#34;基本信息&#34;&gt;基本信息&lt;/h2&gt;&#xA;&lt;p&gt;论文地址：https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125&lt;/p&gt;&#xA;&lt;p&gt;github:&lt;a href=&#34;https://github.com/maziarraissi/PINNs&#34;&gt;maziarraissi/PINNs: Physics Informed Deep Learning: Data-driven Solutions and Discovery of Nonlinear Partial Differential Equations&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;摘要和背景&#34;&gt;摘要和背景&lt;/h2&gt;&#xA;&lt;p&gt;我们介绍了物理信息神经网络 – 经过训练以解决监督学习任务的神经网络，同时遵守由一般非线性偏微分方程描述的任何给定物理定律。在这项工作中，我们展示了我们在解决两大类问题的背景下的发展：数据驱动的解决方案和数据驱动的偏微分方程发现。根据可用数据的性质和排列方式，我们设计了两种不同类型的算法，即&lt;em&gt;&lt;strong&gt;连续时间和离散时间模型&lt;/strong&gt;&lt;/em&gt;。第一种类型的模型形成了一个新的数据高效时空函数逼近器系列，而后一种类型允许使用具有无限阶段数的任意精确的隐式 Runge-Kutta 时间步进方案。通过流体、量子力学、反应扩散系统和非线性浅水波传播中的一系列经典问题证明了所提出的框架的有效性。&lt;/p&gt;&#xA;&lt;p&gt;随着可用数据和计算资源的爆炸性增长，最近在机器学习和数据分析方面的进展已经在各个科学领域取得了变革性的成果，包括图像识别[1]、认知科学[2]和基因组学[3]。然而，在分析复杂的物理、生物或工程系统的过程中，数据获取的成本往往是禁止性的，我们不可避免地面临着在部分信息下进行决策的挑战。在这种小数据环境下，大多数最先进的机器学习技术（例如深度/卷积/递归神经网络）缺乏鲁棒性，并且无法提供收敛性的保证。在第一眼看来，训练一个深度学习算法来准确识别一个非线性映射从几个 - 可能非常高维 - 输入和输出数据对似乎是幼稚的。幸运的是，对于许多与物理和生物系统建模有关的案例，&lt;em&gt;&lt;strong&gt;存在大量的先验知识，这些知识目前尚未在现代机器学习实践中被利用&lt;/strong&gt;&lt;/em&gt;。无论是原则上的物理定律来描述系统的时间依赖动态，还是一些实证验证的规则或其他领域的专业知识，这些先验信息都可以作为一种正则化因子来约束可接受解的空间大小（例如，在不可压缩流体动力学问题中，通过丢弃任何违反质量守恒原则的非现实流解）。作为回报，将这些结构化信息编码到学习算法中会扩大数据的信息内容，使算法能够快速找到正确的解，并且即使只有很少的训练示例也能很好地泛化。利用结构化先验信息来构造数据高效和物理信息化的学习机器的前景已经在最近的研究中得到了展示[4-6]。在那里，作者们使用高斯过程回归[7]来设计专门针对给定线性算子的函数表示，并能够准确推断解决方案并为数学物理中的几个原型问题提供不确定性估计。Raissi等人[8,9]在推断和系统识别的背景下提出了对非线性问题的扩展。尽管高斯过程在编码先验信息方面具有灵活性和数学优雅性，但处理非线性问题引入了两个重要的限制。首先，在[8,9]中，作者们必须局部线性化任何非线性项，以时间为单位，从而限制了所提方法的适用性，并损害了他们在强非线性环境中的预测准确性。其次，高斯过程回归的贝叶斯性质要求一定的先验假设，这些假设可能会限制模型的表示能力并导致鲁棒性/脆弱性问题，特别是对于非线性问题[10]。&lt;/p&gt;&#xA;&lt;h2 id=&#34;研究内容&#34;&gt;研究内容&lt;/h2&gt;&#xA;&lt;p&gt;在这项工作中，我们采用了一种不同的方法，利用深度神经网络及其作为通用函数逼近器的知名能力。在这种情况下，我们可以直接处理非线性问题，而无需进行任何先验假设、线性化或局部时间步进。我&lt;strong&gt;们利用自动微分的最新发展——这是科学计算中最有用但可能未充分利用的技术之一——对神经网络的输入坐标和模型参数进行微分，以获得物理信息神经网络&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;在这项工作中，我们考虑参数化和非线性偏微分方程，其一般形式为&lt;/p&gt;&#xA;$$&#xA;u_t + \mathcal{N}[u ; \lambda] = 0, \, x \in \Omega, \, t \in [0, T]&#xA;$$&lt;p&gt;其中, $u(t, x)$是一个潜在解，$\mathcal{N}[\cdot, \lambda]$是由$\lambda$确定的非线性算子&lt;/p&gt;&#xA;&lt;p&gt;首先，定义&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gnuradio Wsl</title>
      <link>https://koinin.github.io/post/2024/12/14/gnuradio-wsl/</link>
      <pubDate>Sat, 14 Dec 2024 03:08:12 +0800</pubDate>
      <guid>https://koinin.github.io/post/2024/12/14/gnuradio-wsl/</guid>
      <description>&lt;p&gt;记一个wsl安装gnuradio经历，学校有一个课是使用gnuradio玩usrp，然后建议在linux上安装，本次安装主要设计wsl上安装gnuradio。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://wiki.gnuradio.org/index.php/Main_Page&#34;&gt;GNU Radio&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;首先没得说&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;image/index/1734117151613.png&#34; alt=&#34;1734117151613&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;选择从源码构建，这里只要你是ubuntu20.04都是可以选3.10的，亲测可以装。&lt;/p&gt;&#xA;&lt;p&gt;如果IMPOERT ERROR了，大概率是LD_PATH没设置好，从源码里面构建步骤里面有具体的设置方法。&lt;/p&gt;&#xA;&lt;p&gt;装好了以后，会有一个GUI界面，会出现一个问题，如果你想设置听广播，但是wsl是没有声卡的，也就没法播放到windows, 我搜索了解决方案就一个，pulsyaudio。这软件很老了&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://research.wmz.ninja/articles/2017/11/setting-up-wsl-with-graphics-and-audio.html&#34;&gt;Setting Up WSL with Graphics and Audio - Mianzhi Wang&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;而且每次启动都很麻烦，你需要找到busid,然后共享，分享给wsl（因为wsl默认是不支持usb的，你需要把usrp分享给wsl他才能读取）, 然后打开pulsyaudio。&lt;/p&gt;&#xA;&lt;p&gt;所以权衡之下，只做此记录，转向双系统，随便划100g硬盘给ubuntu就行，而且感觉原生linux编译快了很多有没有，ubuntu还没有windows这里的合盖休眠问题，合盖后每次启动都很快。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DataMining</title>
      <link>https://koinin.github.io/post/2024/12/10/datamining/</link>
      <pubDate>Tue, 10 Dec 2024 19:17:52 +0800</pubDate>
      <guid>https://koinin.github.io/post/2024/12/10/datamining/</guid>
      <description>&lt;h1 id=&#34;第一章&#34;&gt;第一章&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;这份PPT的内容是关于“大数据分析与挖掘”的课程介绍，由Junming Shao教授主讲。以下是PPT内容的整理和知识点概述，以及一些适当的扩展来帮助你理解记忆：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-课程信息&#34;&gt;1. 课程信息&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;讲师&lt;/strong&gt;：Junming Shao&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;课程网站&lt;/strong&gt;：dm.uestc.edu.cn&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;教材&lt;/strong&gt;：《Mining of Massive Datasets》和《Data Mining：Concept and Techniques》&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;在线公开课&lt;/strong&gt;：包括“Mining of Massive Datasets”和“Machine Learning”（Andrew Ng）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-课程内容&#34;&gt;2. 课程内容&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;大数据分析入门&lt;/strong&gt;（Lixin Duan）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据挖掘基础&lt;/strong&gt;（Lixin Duan）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;哈希技术&lt;/strong&gt;（Lixin Duan）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;抽样技术&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据流挖掘&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;图挖掘&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hadoop-Spark技术&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;自然语言处理/语言模型&lt;/strong&gt;（Ke Qin）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-先修知识&#34;&gt;3. 先修知识&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;基础算法&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;概率与统计&lt;/strong&gt;（包括概率、贝叶斯等）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;线性代数&lt;/strong&gt;（矩阵理论）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;编程&lt;/strong&gt;（Java/C++/Python等）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据库系统&lt;/strong&gt;（SQL、关系数据库）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-课堂期望&#34;&gt;4. 课堂期望&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;遵守课堂规则&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;尽最大努力参与课堂活动、作业和测试&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-评估方式&#34;&gt;5. 评估方式&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;深入报告&lt;/strong&gt;：占40%&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;课堂活动&lt;/strong&gt;：占10%&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;闭卷期末考试&lt;/strong&gt;：占50%&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-大数据时代&#34;&gt;6. 大数据时代&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;我们生活在哪个时代？&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;大数据在各领域的应用&lt;/strong&gt;：媒体/娱乐、医疗保健、工业、电子商务等&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;大数据的例子&lt;/strong&gt;：Flickr、YouTube、Web视频观看、数字照片、Yahoo! Webmap、人类基因组等&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-大数据的推动因素&#34;&gt;7. 大数据的推动因素&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据存储&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;计算能力&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据可用性&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-大数据的定义和特征&#34;&gt;8. 大数据的定义和特征&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：大数据是指难以使用传统数据库和软件技术处理的大量结构化和非结构化数据。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：通常被称为4V（Volume、Velocity、Variety、Veracity）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-数据挖掘的历史和发展&#34;&gt;9. 数据挖掘的历史和发展&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;1989年IJCAI工作坊&lt;/strong&gt;：知识发现在数据库中&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1991-1994年&lt;/strong&gt;：知识发现在数据库的工作坊&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1995-1998年&lt;/strong&gt;：知识发现在数据库和数据挖掘的国际会议（KDD’95-98）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1997年&lt;/strong&gt;：数据挖掘和知识发现杂志&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-数据挖掘的潜在应用&#34;&gt;10. 数据挖掘的潜在应用&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;市场分析与管理&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;企业分析与风险管理&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;欺诈检测与挖掘异常模式&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-数据挖掘的主要任务&#34;&gt;11. 数据挖掘的主要任务&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;关联规则挖掘&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;聚类分析&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;分类/预测&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;异常检测&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-大数据挖掘的主要方向&#34;&gt;12. 大数据挖掘的主要方向&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;规模（Volume）&lt;/strong&gt;：可扩展的数据挖掘算法&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;速度（Velocity）&lt;/strong&gt;：数据流挖掘&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;多样性（Variety）&lt;/strong&gt;：多源或多类型数据挖掘&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;真实性（Veracity）&lt;/strong&gt;：不确定性分析、链接/缺失值预测&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;13-相关材料&#34;&gt;13. 相关材料&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;主要数据挖掘会议&lt;/strong&gt;：ACM SIGKDD、IEEE ICDM、SIAM SDM等&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;主要数据挖掘期刊&lt;/strong&gt;：IEEE Transactions on Knowledge and Data Engineering (TKDE)、SIGKDD Explorations等&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;这份PPT提供了大数据分析与挖掘课程的全面概览，包括课程内容、先修知识、评估方式、大数据的定义和特征、数据挖掘的历史和发展、潜在应用、主要任务以及大数据挖掘的主要方向。通过这些知识点，你可以对大数据分析与挖掘有一个系统的认识，并了解其在现代技术和社会中的重要性。&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>NextWebConflict</title>
      <link>https://koinin.github.io/post/2024/12/09/nextwebconflict/</link>
      <pubDate>Mon, 09 Dec 2024 20:55:15 +0800</pubDate>
      <guid>https://koinin.github.io/post/2024/12/09/nextwebconflict/</guid>
      <description>&lt;p&gt;记录一个遇到的名称冲突问题，使用one-api作为api管理的时候，如果要使用claude的模型，但是chatgptnextweb已经内置了claude的模型名称，会引发冲突，所以可以在custom models中加入：&lt;/p&gt;&#xA;&lt;p&gt;+claude-3-5-sonnet-20241022@OpenAI=claude-3-5-sonnet-20241022&lt;/p&gt;&#xA;&lt;p&gt;注意，还支持扩展用法，以下就是隐藏了所有模型，然后增加了claude, gemini，当然这里的gemini还是走的默认的google接口，而claude走的OpenAI的接口（也就是我们oneapi的接口）：&lt;/p&gt;&#xA;&lt;p&gt;-all,+gemini-1.5-flash,+claude-3-5-sonnet-20241022@OpenAI=claude-3-5-sonnet-20241022&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM_batch_reference</title>
      <link>https://koinin.github.io/post/2024/12/06/llm_batch_reference/</link>
      <pubDate>Fri, 06 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/12/06/llm_batch_reference/</guid>
      <description>&lt;p&gt;[toc]&lt;/p&gt;&#xA;&lt;h1 id=&#34;llama-31-70b的部署和批量推理离线推理&#34;&gt;Llama-3.1-70b的部署和批量推理（离线推理）&lt;/h1&gt;&#xA;&lt;p&gt;offline inferencem, or batch inference&lt;/p&gt;&#xA;&lt;h3 id=&#34;top_p-vs-top_k&#34;&gt;top_p vs top_k&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;code&gt;top_p&lt;/code&gt;是指在生成文本时，选择概率最高的 &lt;code&gt;p&lt;/code&gt;个token作为候选集。例如，如果 &lt;code&gt;top_p&lt;/code&gt;为0.9，则意味着在生成文本时，选择概率最高的90%的token作为候选集。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;top_p&lt;/code&gt;的作用是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;限制生成的文本的多样性：通过选择概率最高的token，&lt;code&gt;top_p&lt;/code&gt;可以限制生成的文本的多样性，使得生成的文本更加集中和可预测。&lt;/li&gt;&#xA;&lt;li&gt;提高生成的文本的质量：通过选择概率最高的token，&lt;code&gt;top_p&lt;/code&gt;可以提高生成的文本的质量，使得生成的文本更加流畅和自然。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;top_k&lt;/code&gt;是指在生成文本时，选择前 &lt;code&gt;k&lt;/code&gt;个概率最高的token作为候选集。例如，如果 &lt;code&gt;top_k&lt;/code&gt;为100，则意味着在生成文本时，选择前100个概率最高的token作为候选集。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;top_k&lt;/code&gt;的作用是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提高生成的文本的多样性：通过选择前 &lt;code&gt;k&lt;/code&gt;个概率最高的token，&lt;code&gt;top_k&lt;/code&gt;可以提高生成的文本的多样性，使得生成的文本更加丰富和多样。&lt;/li&gt;&#xA;&lt;li&gt;降低生成的文本的质量：通过选择前 &lt;code&gt;k&lt;/code&gt;个概率最高的token，&lt;code&gt;top_k&lt;/code&gt;可以降低生成的文本的质量，使得生成的文本更加随机和不确定。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;top_p&lt;/code&gt;和 &lt;code&gt;top_k&lt;/code&gt;是两个相关但不同的参数。&lt;code&gt;top_p&lt;/code&gt;限制了生成的文本的多样性，而 &lt;code&gt;top_k&lt;/code&gt;提高了生成的文本的多样性。通常情况下，&lt;code&gt;top_p&lt;/code&gt;和 &lt;code&gt;top_k&lt;/code&gt;会被同时使用，以便在生成的文本的质量和多样性之间找到一个平衡。&lt;/p&gt;&#xA;&lt;p&gt;例如，如果你想生成一个高质量的文本，你可以设置 &lt;code&gt;top_p&lt;/code&gt;为0.9和 &lt;code&gt;top_k&lt;/code&gt;为100。这意味着在生成avour时，选择概率最高的90%的token作为候选集，并从候选集中选择前100个概率最高的token作为生成的文本。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;huggingface-model&#34;&gt;Huggingface model&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;huggingface-cli login&#xD;&#xA;huggingface-cli download -h&#xD;&#xA;huggingface-cli download meta-llama/Llama-3.1-70B-Instruct&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;vllm&#34;&gt;Vllm&lt;/h2&gt;&#xA;&lt;h3 id=&#34;cuda和pytorch&#34;&gt;CUDA和Pytorch&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/null_one/article/details/129412159&#34;&gt;显卡驱动CUDA 和 pytorch CUDA 之间的区别_cuda版本和torch.cuda一样吗-CSDN博客&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;区别了nvcc nvidia-smi torch.__version__&lt;/p&gt;&#xA;&lt;h3 id=&#34;conda和pip&#34;&gt;conda和pip&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/Li-JT/p/14024034.html&#34;&gt;conda install和pip install区别 - lmqljt - 博客园&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;pip 包含build conda一般是可执行&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;安装环境 此处安装的是老版vllm 支持cuda11.8&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;# conda 虚拟环境&#xD;&#xA;conda create myenv&#xD;&#xA;&#xD;&#xA;# 先安装pytorch&#xD;&#xA;conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia&#xD;&#xA;&#xD;&#xA;# Install vLLM with CUDA 11.8.&#xD;&#xA;export VLLM_VERSION=0.6.1.post1&#xD;&#xA;export PYTHON_VERSION=310&#xD;&#xA;pip install https://github.com/vllm-project/vllm/releases/download/v${VLLM_VERSION}/vllm-${VLLM_VERSION}+cu118-cp${PYTHON_VERSION}-cp${PYTHON_VERSION}-manylinux1_x86_64.whl --extra-index-url https://download.pytorch.org/whl/cu11&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;代码&#xA;注意这里的要指定 &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;， 而且在代码内支持着一种方式&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/m0_65814643/article/details/143882882&#34;&gt;【杂记】vLLM如何指定GPU单卡离线推理_vllm指定gpu-CSDN博客&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>RalativePath</title>
      <link>https://koinin.github.io/post/2024/11/18/ralativepath/</link>
      <pubDate>Mon, 18 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/11/18/ralativepath/</guid>
      <description>&lt;p&gt;一般来说，我们写markdown的图片都是存储在index.md同目录下的assets/文件夹里面，但是hugo不能识别到这个文件夹，所以我们在写markdown的时候需要创建一个文件夹，such as:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;RelativePath/&#xA;    assets/&#xA;    imdex.md&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;公式&lt;/p&gt;&#xA;$$x_{x+1}$$</description>
    </item>
    <item>
      <title>Text2cad</title>
      <link>https://koinin.github.io/post/2024/11/17/text2cad/</link>
      <pubDate>Sun, 17 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/11/17/text2cad/</guid>
      <description>&lt;h1 id=&#34;基本信息&#34;&gt;基本信息&lt;/h1&gt;&#xA;&lt;p&gt;论文地址：http://arxiv.org/abs/2409.17106&#xA;repository: &lt;a href=&#34;https://sadilkhan.github.io/text2cad-project/&#34;&gt;https://sadilkhan.github.io/text2cad-project/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;摘要与背景&#34;&gt;摘要与背景&lt;/h1&gt;&#xA;&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;&#xA;&lt;p&gt;在现代软件中制作复杂的计算机辅助设计 (CAD) 模型原型可能非常耗时。这是由于缺乏能够快速生成更简单的中间零件的智能系统。我们提出了 Text2CAD，这是第一个使用适合所有技能水平的设计师友好指令生成文本到参数 CAD 模型的 AI 框架。此外，我们引入了一个数据注释管道，用于使用 Mistral 和 LLaVA-NeXT 根据 DeepCAD 数据集的自然语言指令生成文本提示。该数据集包含 ~ 170K 个模型和 ~ 660K 个文本注释，从抽象 CAD 描述（例如，生成两个同心圆柱体）到详细规范（例如，绘制两个以 (x, y) 为中心、半径为 r1、r2 的圆，并沿d 后正常&amp;hellip;）。在 Text2CAD 框架内，我们提出了一种基于端到端 Transformer 的自回归网络，用于从输入文本生成参数化 CAD 模型。我们通过多种指标来评估模型的性能，包括视觉质量、参数精度和几何精度。我们提出的框架在人工智能辅助设计应用中显示出巨大的潜力。项目页面位于 &lt;a href=&#34;https://sadilkhan.github.io/text2cad-project/&#34;&gt;https://sadilkhan.github.io/text2cad-project/&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;可以将其结合设计，为中间件模型创建文本提示（零件和参数），可以方便搜索&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;创新点&#34;&gt;创新点&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;作为第一个使用文本描述生成参数化 3D CAD 模型的 AI 框架&lt;/li&gt;&#xA;&lt;li&gt;提出了一个数据注释管道，它利用LLM 和VLM 生成一个数据集，其中包含具有不同复杂程度和参数细节的文本提示&lt;/li&gt;&#xA;&lt;li&gt;提出了一种基于端到端 Transformer 的自回归架构，用于根据输入文本提示生成 CAD 设计历史记录。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;研究内容&#34;&gt;研究内容&lt;/h1&gt;&#xA;&lt;h2 id=&#34;算法定义&#34;&gt;算法定义&lt;/h2&gt;&#xA;&lt;h3 id=&#34;text2cad数据标注&#34;&gt;Text2CAD数据标注&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20241117232131281.png&#34; alt=&#34;image-20241117232131281&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;使用vllm进行形状描述&lt;/p&gt;&#xA;&lt;p&gt;首先从预定的摄像机角度为每个单独的零件和最终的 CAD 模型生成多视图图像。然后，这些图像在 LLaVANeXT [25] 模型的预定义提示&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多层级设计架构&lt;/p&gt;&#xA;&lt;p&gt;DeepCAD [55] 数据集包含 JSON 格式的 CAD 构造序列。我们首先使用“最小元数据生成器”对原始 CAD 构造序列进行预处理，该生成器用更有意义的术语（例如“part_1”、“loop_1”）替换随机、无意义的键。&lt;/p&gt;</description>
    </item>
    <item>
      <title>记录一次zsh配置流程</title>
      <link>https://koinin.github.io/post/2024/11/03/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1zsh%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Sun, 03 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/11/03/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1zsh%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;记录一次zsh配置流程（zsh + oh my zsh）&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;DD系统&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/bin456789/reinstall&#34;&gt;https://github.com/bin456789/reinstall&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;安装zsh&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code&gt;apt install zsh -y&#xD;&#xA;chsh -s /bin/zsh&#xD;&#xA;# reboot&#xD;&#xA;&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;安装 OMZ&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code&gt;sh -c &amp;quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&amp;quot;&#xD;&#xA;&#xD;&#xA;# 配置文件&#xD;&#xA;~/.zshrc&#xD;&#xA;&#xD;&#xA;# 插件&#xD;&#xA;~/.oh-my-zsh/custom/plugins&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Mamba2 pre-trained model使用</title>
      <link>https://koinin.github.io/post/2024/08/12/mamba2-pre-trained-model%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/08/12/mamba2-pre-trained-model%E4%BD%BF%E7%94%A8/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;参考 &lt;a href=&#34;https://github.com/vasqu/mamba2-torch&#34;&gt;https://github.com/vasqu/mamba2-torch&lt;/a&gt; &amp;gt; &lt;a href=&#34;https://huggingface.co/AntonV/mamba2-130m-av&#34;&gt;https://huggingface.co/AntonV/mamba2-130m-av&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;这里用的是作者自己转换的mamba2参数模型（从原始版本转换成hf的transfromer兼容版本），并提供了一个本地包，但是安装包的时候出现一点问题，版本不符合 需要把requirements.txt中的torch triton==2.2.0 改成你现在的版本，我测试没什么问题&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux terminal 美化</title>
      <link>https://koinin.github.io/post/2024/08/11/linux-terminal-%E7%BE%8E%E5%8C%96/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/08/11/linux-terminal-%E7%BE%8E%E5%8C%96/</guid>
      <description>&lt;p&gt;通过.bashrc美化shell&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;PS1=&amp;quot;\[\e[01;37m\]\t \[\e[01;32m\]\u\[\e[37m\]@\h \[\e[36m\]\w\[\e[m\]\\$ &amp;quot;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;通过.vimrc美化vim&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;syntax on &amp;quot; 设置语法高亮 &#xA;set nocompatible&#xA;set nu &amp;quot; 设置行数显示 &#xA;set tabstop=4 &amp;quot; 设置tab缩进长度为4空格 &#xA;set autoindent &amp;quot; 设置自动缩进，适用所有类型文件 &#xA;set cindent &amp;quot; 针对C语言的自动缩进功能，在C语言的编程环境中，比autoindent更加精准 &#xA;set list lcs=tab:\\|\\ &amp;quot; 设置tab提示符号为 &amp;quot;|&amp;quot;，注意最后一个反斜杠后面要留有空格 &#xA;set cc=0 &amp;quot; 设置高亮的列，这里设置为0，代表关闭 set cursorline &amp;quot; 突出显示当前行 &#xA;set showmode &#xA;set showcmd &#xA;set mouse =a &#xA;set t_Co=256 &#xA;set relativenumber &#xA;set noerrorbells &#xA;set vb t_vb=&#xA;set encoding=utf-8 &#xA;set termencoding=utf-8&#xA;&#xA;set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr &#xA;set fileencoding=utf-8 &#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>极乐迪斯科（Disco Elysium）游玩体验</title>
      <link>https://koinin.github.io/post/2024/08/10/%E6%9E%81%E4%B9%90%E8%BF%AA%E6%96%AF%E7%A7%91disco-elysium%E6%B8%B8%E7%8E%A9%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Sat, 10 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/08/10/%E6%9E%81%E4%B9%90%E8%BF%AA%E6%96%AF%E7%A7%91disco-elysium%E6%B8%B8%E7%8E%A9%E4%BD%93%E9%AA%8C/</guid>
      <description>&lt;h2 id=&#34;极乐迪斯科disco-elysium游玩体验&#34;&gt;极乐迪斯科（Disco Elysium）游玩体验&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;写于2024-08-10 游戏时长18.9h&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;很诚挚的定论她，这是我开始玩单机以来，第一部不会感到倦怠的作品。每一次剧情推动，都认真的考虑剧情的走向，每一个角色都是下了大功夫的塑造关系，性格，寓意。伏笔从始至终，不是工业化流水线，甚至旁白都是大量的配音，沉浸到思维的碰撞中。不得不过，要翻译这样一部作品是很困难的，各类思维的表达方式不同，文本前后联系。对这样的一部作品我觉得是有必要探讨他的寓意的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;diving-into-disco&#34;&gt;diving into Disco&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;你可以随意向市民们提问，人们总是对拥有权力的人保持宽容，特别是你警官。 &amp;gt; &amp;gt; 非原话&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Disco是什么？一切从Disco，酒精，毒品，性爱开始，你分配的每一个技能点数，都与政治立场无关，只决定你和人的交流进展。正如马哲说，人的存在就是人的社会关系。我们所熟知的领袖，也只不过在其中某些点数过于常人。当然，玩家无所不能，一次又一次的骰子掷下，我们开始逐渐进入这个城市。这个故事发生的城市很小，不过麻雀虽小，却包含一个港口，公路要塞，小岛，教堂，渔村。&lt;/p&gt;&#xA;&lt;p&gt;一个灵魂从一个腐朽的身体里诞生了，你，失忆了。这个城市看起来很不友好，康米主义分子，极端种族主义，极端自由主义，中立派相互对立。而这样一片土地曾经发生过什么呢，君主专制，大革命，大革命的失败，无政府，自由主义，无数制度都存在过这篇土地，都留下过自己的痕迹。&lt;/p&gt;&#xA;&lt;p&gt;竹节虫是什么，逃兵是什么，为什么逃兵看不到竹节虫，为什么又要嫉妒那个吊人和女人，为什么他要偷窥女人，为什么他要威胁女人，为什么坤诺表现得如何疯狂，为什么工会如此排外，为什么不同的人格都出现在同一具腐朽的身体里，警察是什么，我是谁?&lt;/p&gt;&#xA;&lt;p&gt;当资本主义和人民分手，本来曾经康米内在化的我将如何面对这个矛盾重重的世界？&lt;/p&gt;</description>
    </item>
    <item>
      <title>明末·饿殍千里行游戏体验</title>
      <link>https://koinin.github.io/post/2024/08/07/%E6%98%8E%E6%9C%AB%E9%A5%BF%E6%AE%8D%E5%8D%83%E9%87%8C%E8%A1%8C%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/08/07/%E6%98%8E%E6%9C%AB%E9%A5%BF%E6%AE%8D%E5%8D%83%E9%87%8C%E8%A1%8C%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;2024-08-07 &amp;gt; 啊哈哈，最近高强度游戏，游戏体验出的太快了，我写体验，就不能只体验，会随着时间写我的一些吐槽把&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;看到那个“安”字，不知道为什么想起了盗官记。就想写一个盗官记改编，希望不是废案吧。零创产量挺高的啊，最近出这么多游戏，暗黑桃花源其实不错，画风也不错，有Raging loop的味道。那个二分之一画风差距巨大，我其实更喜欢黑色阵营，不过游戏太难玩&amp;hellip;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;阿巴阿巴阿巴~&lt;/p&gt;&#xA;&lt;p&gt;挺平淡的展开，作画有好有坏，经费都花在了该花的地方是吧（笑~）。&lt;/p&gt;&#xA;&lt;p&gt;怎么和带小孩一样&amp;hellip;Hanser配音还是很出戏啊，明显在藏刀啊，舌头挺正常一个人。开始的令牌感觉有伏笔。故事太短，总感觉人物刻画不够。&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;卖给身边不愁吃喝的亲友&amp;rdquo;。我要是有亲友还至于干这行吗（笑。&lt;/p&gt;&#xA;&lt;p&gt;穗穗这家世够惨的，其实选明朝还挺合适的，毕竟王爷多。穗穗这后面的剧情&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;其实你单单要写，完全可以把两件事拆开，对穗穗的感情混杂着对王侯将相的愤慨，显得主次不清，没有感觉悲壮。倒是李自成的形象挺帅的，又来一个想当皇帝的。&lt;/p&gt;&#xA;&lt;p&gt;总之全篇我最有印象的还是穗穗有多惨，而这不过是一个王朝末期的剪影而已。&lt;/p&gt;&#xA;&lt;p&gt;最后，仅以此篇献给所有动手实现”不再有饿殍“的人&lt;/p&gt;&#xA;&lt;p&gt;剧情一般，打分的话，3.1/5&lt;/p&gt;</description>
    </item>
    <item>
      <title>Steins;Gate 游戏体验</title>
      <link>https://koinin.github.io/post/2024/08/06/steinsgate-%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/08/06/steinsgate-%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;2024-08-06&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;确实是一部很慢热的游戏，剧情前一半多都是日常，直到SERN破门而入我还以为是凶真的幻想，自此剧情开始突然黑残深，我当然想要挽回铃羽啊，可是世界的惯性决定，胸针如果不想牺牲什么。是达不到目的的，从男主收到那条短信开始，命运已经决定了，你不是在拯救，你是去换，到最后还剩下了什么呢？记忆太多会改变一个人的，当一个人不把记忆当回事的时候，就容易崩坏了。 桶子真男人，不愧有个这么好的女儿。红莉栖确实是助手，和胸针一唱一和，主打一个反差萌。铃羽最后的一年太让人心疼了。 PS，布朗管女儿的那张原画是真的吓人&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;菲莉丝结局，放弃了时间机器，SERN也没上门。 所以一开始使用时间机器直接或者间接的导致了后面的IBN消失，胸针只不过现在走着一条修正时间线的路，既然如此，直接回到最初，拒绝时间机器的诱惑。 直接让他爸以IBN作为赎金给神社，岂不是美哉！（~~~我是天才~~~） 怪不得菲莉丝之前一直赢，原来是读心术&amp;hellip;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;秀吉啊，秀吉 唉，老是搞这种约会，离别的时候怎么放得下嘛，你看摄影小子就不专业，男的不是更好？！微小的调整是修改不了时间线的，不要有这样的想法。 游戏完全参照了设定，其实是线性的叙事结构，所有的结局都是分支结局，虽然并不完美。 还是没法接受&amp;hellip;人命换性别？你已经牺牲了两个人的希望了，为什么半路放弃了。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;谁都可以牺牲，一切为了真由里 2. 回到最初，从头开始！已经赎完了所有的罪，我们选择最后的结局。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;其实在理论方面有所不完善，但是只要用时间是完全线性就可以解释，如果是我来写，原来的β时间线因为助手死了，所以男主跳跃到了其他时间线，而本来的β时间线停滞了，这时候，胸针是不知道死没死的，而胸针穿越回来后的β时间线，因为此时的胸针记忆和之前不同其实不是原本的时间线，然后经过十年的计算和研究，找到了肉身穿越的方法，但是由于主角团都不能和现在的自己碰面，所以只能由桶子的女儿来传信和救出重伤的胸针，不然胸针如果死了，蝴蝶效应又会产生，胸针要做到少改变状态的同时，还能通过这个时间黑盒得到自己想要的结果。所以拯救助手的是记忆，从一开始就已经确定了的记忆。&lt;/p&gt;&#xA;&lt;p&gt;理论不是很严谨，但是内容确实很催泪，一次又一次的放弃，只为了最后能救回助手。顺便一提，出生父亲。&lt;/p&gt;</description>
    </item>
    <item>
      <title>记录一次服务器跑大模型经历</title>
      <link>https://koinin.github.io/post/2024/07/31/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B7%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%8F%E5%8E%86/</link>
      <pubDate>Wed, 31 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/07/31/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B7%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%8F%E5%8E%86/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;由于网络问题，速度慢或者无法直连hugging-face docker hub pipy&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;设置系统代理&#34;&gt;设置系统代理&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;# set proxy config via profie.d - should apply for all users &#xA;export http_proxy=&amp;quot;http://127.0.0.1:10000/&amp;quot; &#xA;export https_proxy=&amp;quot;http://127.0.0.1:10000/&amp;quot; localhost&amp;quot;&#xA;&#xA;# 注意，jupyter是不会直接调用你的bash设置的，所以你需要在cell先设置一下系统代理，这样jupyter笔记本就会调用你的代理了&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;pipy-使用国内镜像我用的清华镜像也可以用其他的&#34;&gt;Pipy 使用国内镜像，我用的清华镜像，也可以用其他的&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;# pipy 如果你配置了代理，就可以不用设置这个源了&#xA;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;docker-主要是连接docker-hub-比较吃力-可以选1panel的镜像&#34;&gt;Docker 主要是连接docker hub 比较吃力 可以选1panel的镜像&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39; { &amp;quot;registry-mirrors&amp;quot;: \[ &amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;, &amp;quot;https://docker.nju.edu.cn&amp;quot;, docker.1panel.live \] } EOF sudo systemctl daemon-reload sudo systemctl restart docker &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;深度学习环境配置-这里有两种方案--方案一-只有pytorchjupyter--refer---httpshubdockercomrtverouspytorch-notebook&#34;&gt;深度学习环境配置 这里有两种方案 #### 方案一-只有pytorch+jupyter &amp;gt; refer -&amp;gt; &lt;a href=&#34;https://hub.docker.com/r/tverous/pytorch-notebook&#34;&gt;https://hub.docker.com/r/tverous/pytorch-notebook&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;这里面是没有nvcc的需要在以下网站里安装 &amp;gt; refer -&amp;gt; &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34;&gt;https://developer.nvidia.com/cuda-downloads&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>有关White album2一点点想法</title>
      <link>https://koinin.github.io/post/2024/07/28/%E6%9C%89%E5%85%B3white-album2%E4%B8%80%E7%82%B9%E7%82%B9%E6%83%B3%E6%B3%95/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/07/28/%E6%9C%89%E5%85%B3white-album2%E4%B8%80%E7%82%B9%E7%82%B9%E6%83%B3%E6%B3%95/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;和纱，你说我是不是真的坏掉了呢？&#xA;小木曾雪菜&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;关于白色相簿2&#34;&gt;关于白色相簿2&lt;/h2&gt;&#xA;&lt;p&gt;作为游玩的比较晚的玩家，其实一起很好奇为什么这么多人是所谓的白学家，怎样一个作品才能在玩家群体引起这样的风波，在几十个小时的心理折磨后，终于写下了这篇观后感，我会尝试用一点诙谐的感觉写出我记忆里的观后感。 白2总共大致分为三部，没有选择的少年时期，遇得到的人都是上天已经注定好的；因为年少时犯的错，没有做到的事导致的青年；往事开始回首的晚年，是坚持本心还是走向崩坏。 故事的起点就是我人生遗憾的起点，我年轻的时候啊，也有一个闲暇时飘出钢琴声的音乐教室呢，放学那天我和朋友说，嘿，你知道吗，那个妹子，我一定要拿下。友人A说，你还是先把对线拿下，别玩你那b卡牌了，卡牌没出路的。我反驳，我卡牌猛地一，不信solo?友人B补充，走走，这周末我带你们乱杀。我一直很自信自己的卡牌大师，裁决第一AD打野卡牌，这么多前缀是我自信的本钱。&lt;/p&gt;&#xA;&lt;h3 id=&#34;关于冬马和纱&#34;&gt;关于冬马和纱&lt;/h3&gt;&#xA;&lt;p&gt;一个记忆里高冷的女孩子，哪怕你的时光飞逝，她总是驻足在那样一间音乐室里，音乐室只不过一个黑衣女孩和一架钢琴而已，而已。换做后来的我，还愿意去打开这样的一扇门吗，还愿意承担这样的独特的记忆吗？ 这样一个女孩子怎么能喜欢上我呢？首先你得有自己的闪耀点吧，当天晚上我挑灯夜战，终于研究出了一套打野的秘籍，怂。朋友们看我总是不离开野区恨得牙痒痒，我告诉他们，等我刷出来，就能翻盘，你们先顶住，我继续去折腾我的吞噬者打野刀。或许我有一点点天赋，只不过稍微努力，就拿到了班上的第二名，成绩就是年轻的我的装逼本钱。我自感觉自己有了追她的资本，就开始怂恿我的朋友们帮我追她。 只不过感情这个事情，说来简单，谁也不知道是怎么来的。只不过我的故事就此而结束了，没有下一节，年少的轻狂最终只是遗憾，看似若即若离的关系，同样伴随着升学，两个人走向了背向。 我其实不知道那时的我是怎样的一个位置，是不是在她心里也有一席之地，哪怕现在的我也会回答不聊这个问题。 她是我的人生之光，普罗米修斯偷盗来的宙斯之火，冬-马-和-纱，这样随意的几个词的简单组合，却是像是伴随人类之火的潘多拉魔盒，美丽而致命，也让我的心遭受日晒雨淋。 就像选择了和纱一样，我享受了内心的满足，却只能接受这个内心容器的拷打，哪怕这时候的我再幸福，终究终究灾难在这片大地留下的是千沟万壑。&lt;/p&gt;&#xA;&lt;h3 id=&#34;关于小木曾雪菜&#34;&gt;关于小木曾雪菜&lt;/h3&gt;&#xA;&lt;p&gt;IC篇幅其实已经把雪菜勾绘出一个大概了，闪光的外表下其实也是有着自己小孩子的一面，她看似和谁都很好，但是却是和谁都疏远，也只有一个心细的男生能找到她内心的弱点。但是那个下雪的夜晚彻底让三个人的命运走向了渐行渐远的方向。 我的内心是守序善良的，所以我选择救赎雪菜，也是救赎我因为自己的错误而让她失去的三年，我已经伤害过她一次了，又怎么能伤害她。这不仅是一种弥补，也是一种救赎，放下了曾经的自己，认识到自己的幼稚。这三年我常常会想，我是不是错了了什么，当时如果我坚持是不是结构又会不一样呢，是不是我还有哪里做的不好。 爱是一种陪伴，或许可以解释为一种习惯，当我习惯了一个人，她总是能接受我，哪怕我选择了背叛，哪怕我选择了说谎，哪怕我在两个人之中痛苦而快乐。一个你永远可以回到的家，这或许是我，这样一个没有家庭的我真正想要的。 那么多的世界线，她总是陪在我身边，没有一次例外，她甚至愿意分享爱，三个人的爱。&lt;/p&gt;&#xA;&lt;h3 id=&#34;关于和泉千晶&#34;&gt;关于和泉千晶&lt;/h3&gt;&#xA;&lt;p&gt;这是最后一个角色了，她的出现很突兀，结束了我痛苦的游戏时长，在她身边，我可以不去在乎是不是伤害到雪菜，在他身边，我可以忘掉和纱，只有在他身边，我才可以接受我自己的软弱，正视我曾经犯下的错误。 我很轻松，她的生命需要我，我也需要她，直到某天，她消失了。 雪菜是多么好啊，她总是能接受如何的我，即使我不断地去伤害她，即使我在无数选择中错过了她。和纱是多么好啊，年少时的爱是多么难得，年少时的遗憾又是多么意难平。 很可惜，我的人生没有这样的一个人来救赎我，是我不配得到这样的爱意，这样参杂着利用和真挚的爱意。千晶的爱纯粹吗？我想不是的，那又怎么样呢，爱又何必纯粹，人也太复杂了。&lt;/p&gt;&#xA;&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;就快了，就快了啊&#xA;和泉千晶&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;我喜欢雪菜，我喜欢和纱，两个人我都只能选择伤害。人生其实少年就死了，只不过晚年才开始赎罪。&lt;/p&gt;</description>
    </item>
    <item>
      <title>有关魔法使之夜</title>
      <link>https://koinin.github.io/post/2024/07/28/%E6%9C%89%E5%85%B3%E9%AD%94%E6%B3%95%E4%BD%BF%E4%B9%8B%E5%A4%9C/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/07/28/%E6%9C%89%E5%85%B3%E9%AD%94%E6%B3%95%E4%BD%BF%E4%B9%8B%E5%A4%9C/</guid>
      <description>&lt;h2 id=&#34;魔法使之夜&#34;&gt;魔法使之夜&lt;/h2&gt;&#xA;&lt;p&gt;某种程度上是我的型月的入门作(空之境界很早之前看的，但是没看懂)，你要说感动，更多的是产生了不少好奇对这样一个故事的背景。 对两位女主角的描述，我更愿意称其为魔女之夜(笑 其实作品主要还是战斗，真正做到了文字描述战斗的极限，配合动图。 红发青子点燃了我的战斗之魂，不愧是第五魔法使。 所以，魔法使背后的世界，是怎么样的呢？ 逐渐走入Fate的大坑了呢&lt;/p&gt;&#xA;&lt;h2 id=&#34;fsn&#34;&gt;FSN&lt;/h2&gt;&#xA;&lt;p&gt;补上一个fsn的体验，三条线最喜欢的还是凛。saber和樱是毫无感觉啊&lt;/p&gt;</description>
    </item>
    <item>
      <title>关于摄影有感而发</title>
      <link>https://koinin.github.io/post/2024/05/15/%E5%85%B3%E4%BA%8E%E6%91%84%E5%BD%B1%E6%9C%89%E6%84%9F%E8%80%8C%E5%8F%91/</link>
      <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/05/15/%E5%85%B3%E4%BA%8E%E6%91%84%E5%BD%B1%E6%9C%89%E6%84%9F%E8%80%8C%E5%8F%91/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;松下G85搭配松下1445镜头&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;首先，为什么选松下，松下是我老朋友了，作为家电厂，用过他家的台灯。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;PS:我的第一台相机其实是奥巴的，不过是一台数码相机，那时候拍照没有讲究想到什么拍什么，不需要构图，拍照只是为了留恋，而不是为了装逼。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;第一次买相机其实也不太懂，搜索了一些资料就开始上手了，买到了才开始学习，比如机械电子快门，防抖，曝光补偿，iso，超采，以上都很有意思，改善了之前对单反的固有想法。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Ps的Adobe camera raw 可以通过算法实现超采，和去噪点，是对M43传感器不大的一些弥补，但是我如果只处理一张图片，去噪点功能其实对观感而言比超采更好。 也可以通过DXO Photolab实现，但是DXO个人感觉没有ACR效果好。&lt;/li&gt;&#xA;&lt;li&gt;松下的G85可以实现DUAL2 防抖，但是是需要一定的硬件支持的，也就是镜头支持。 &lt;a href=&#34;https://forum.xitek.com/thread-1760716-1-1.html&#34;&gt;https://forum.xitek.com/thread-1760716-1-1.html&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://av.jpn.support.panasonic.com/support/global/cs/dsc/download/index.html&#34;&gt;https://av.jpn.support.panasonic.com/support/global/cs/dsc/download/index.html&lt;/a&gt; 很遗憾，我的1445只能实现镜头防抖，不能协同。不过通过稳定器开启之后对手持改善很大。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;我的客观需要其实不高，但是人嘛，总是在有限的预算里有无限的追求。开始越来越尝试记录自己的生活，这也是一种进步吧，或许只有对生活充满期望，才可以应对我要到哪里去这个问题？&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Day</title>
      <link>https://koinin.github.io/post/2024/05/02/my-first-day/</link>
      <pubDate>Thu, 02 May 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/05/02/my-first-day/</guid>
      <description>&lt;p&gt;Hello world !!!&lt;/p&gt;</description>
    </item>
    <item>
      <title>GCore HK Basic vm</title>
      <link>https://koinin.github.io/post/2024/03/23/gcore-hk-basic-vm/</link>
      <pubDate>Sat, 23 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/03/23/gcore-hk-basic-vm/</guid>
      <description>&lt;p&gt;Gcore作为老牌互联网提供商，早期用过他家的DNS和CDN，体验还是很稳定的，虽然现在我是一个Cloudflare的忠实免费玩家。 GCore的vps分为两种，Core和Edge，Core的物理资源更充沛，Edge更便宜 当然我们只是需要一台简单的服务器做Vlog和脚本服务器使用，所以还是使用Edge,Edge更便宜 Gcore宣称出口流量免费，但是实际上BasicVM的入口也是免费的。虽然Basic VM只有100Mbps的速度，但是实测短时间超过是没有问题的，不过大流量下，我估计CPU和内存都顶不住&amp;hellip;当然CDN还是上了Cloudflare家的免费计划，CloudFlare是真的中小开发者的最佳选择。&lt;/p&gt;&#xA;&lt;p&gt;Done&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gredge</title>
      <link>https://koinin.github.io/post/2024/03/21/gredge/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/03/21/gredge/</guid>
      <description>&lt;p&gt;第一次体验了克系的游戏，虽然游戏剧情开始有点懵，但是之后跟着攻略走，打通了两个结局，还是看懂了一点。&lt;/p&gt;&#xA;&lt;p&gt;男主从海中捡到了书，但是也吸引出了海中的神明。妻子死后，男主后悔了，想要收回之前自己遗失的物品，通过书的力量献祭，复活自己的妻子，但此时，神明终于失去了最后的枷锁，灭世。&lt;/p&gt;&#xA;&lt;p&gt;若是，跟着守塔人的指引，向大海归还书，像多年前那样，大海只会收回男主的姓名。&lt;/p&gt;&#xA;&lt;p&gt;很简单的游戏，剧情流程也很短，不是很喜欢重复的工作，所以dlc没打，整体剧情开始很隐晦，后面很明朗。算是4.0的克系游戏。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vim</title>
      <link>https://koinin.github.io/post/2024/03/20/vim/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/03/20/vim/</guid>
      <description>&lt;p&gt;Vim 简单配置&lt;/p&gt;&#xA;&lt;p&gt;sudo vim ~/.vimrc&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;set number   &amp;quot; 显示行号&#xA;set mouse=a  &amp;quot; 启用鼠标&#xA;set ruler    &amp;quot; 显示标尺（显示当前光标位置的行号、列号）&#xA;set cursorline  &amp;quot; 高亮显示当前行&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;hr&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;更新&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;推荐适用Nvchad&lt;/p&gt;&#xA;&lt;p&gt;安装neovim版本大于0.10，然后就可以开爽&lt;/p&gt;&#xA;&lt;p&gt;&amp;lt;Space + e&amp;gt;打开资源管理器&lt;/p&gt;&#xA;&lt;p&gt;LSP也配置好了&lt;/p&gt;&#xA;&lt;p&gt;&amp;lt;alt + i&amp;gt;打开临时终端&lt;/p&gt;</description>
    </item>
    <item>
      <title>世界，您好！</title>
      <link>https://koinin.github.io/post/2024/03/20/%E4%B8%96%E7%95%8C%E6%82%A8%E5%A5%BD/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/2024/03/20/%E4%B8%96%E7%95%8C%E6%82%A8%E5%A5%BD/</guid>
      <description>&lt;p&gt;欢迎使用 WordPress。这是您的第一篇文章。编辑或删除它，然后开始写作吧！&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Test markdown&lt;/p&gt;&#xA;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://koinin.github.io/post/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/1/01/01/</guid>
      <description>&lt;h2 id=&#34;移动最小乘法mls&#34;&gt;移动最小乘法（MLS）&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主动贝叶斯推断&#xA;信息增益采样、最大化后验提升、主动控制资源采集数据等&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;变分贝叶斯推断&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;贝叶斯神经网络&lt;/li&gt;&#xA;&lt;li&gt;高斯过程&lt;/li&gt;&#xA;&lt;li&gt;移动最小二乘法&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;生成模型&lt;/li&gt;&#xA;&lt;li&gt;使用协方差（半变异）作为数据点之间的相关关系&lt;/li&gt;&#xA;&lt;li&gt;先验的信念会使得任何采样函数都经过采样点&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;todo&#34;&gt;ToDo&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 多目标优化&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;pareto frontiers&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;episilon&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 单纯形法 + 梯度&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;lp问题&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; NPs&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;非常奇怪的输入，字符串？图？&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;为什么我实现不了像单个函数接近那样的性能&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;跑程序&#34;&gt;跑程序&lt;/h2&gt;&#xA;&lt;p&gt;U_complexmethod_visvr_example3.m&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250709093822939.png&#34; alt=&#34;image-20250709093822939&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;example6&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250709152808265.png&#34; alt=&#34;image-20250709152808265&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250709112722660.png&#34; alt=&#34;image-20250709112722660&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;example5&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250709145319973.png&#34; alt=&#34;image-20250709145319973&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250709145235262.png&#34; alt=&#34;image-20250709145235262&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;貌似是代码的问题，明天来解决&lt;img src=&#34;assets%5Cimage-20250709174550206.png&#34; alt=&#34;image-20250709174550206&#34;&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这里应该是example6 kriging u&lt;/p&gt;&#xA;&lt;p&gt;失效概率已经收敛了，但是没有自动停止&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets%5Cimage-20250709174705830.png&#34; alt=&#34;image-20250709174705830&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这里是example5 kriging u&lt;/p&gt;&#xA;&lt;p&gt;明天好好看一下AK_U的代码，是不是收敛条件没写好&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;并且思考一下为什么visvr效果差，不应该效果差这么多啊。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;或者直接使用SVR? 不考虑不确定性的实现了&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250710140635268.png&#34; alt=&#34;image-20250710140635268&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这个例子也是跑了600步完全不收敛，找到问题了&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250710140705307.png&#34; alt=&#34;image-20250710140705307&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250710140752575.png&#34; alt=&#34;image-20250710140752575&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;自己写的kriging调用错误，这里要使用regpoly1，错误的设置成了regpoly0&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;对复合形法有两种理解，&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 一种直接把u作为待优化的函数&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 一种是把已选点作为训练点来寻找下一个点&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-matlab&#34;&gt;function result= AK_U(problem, option)&#xD;&#xA;&#xD;&#xA;variable_table = problem.variable_table;&#xD;&#xA;performanceFunc = problem.performanceFunc;&#xD;&#xA;dim= size(variable_table,1);&#xD;&#xA;N0=3*dim;&#xD;&#xA;N_tianchong=option.Nt;&#xD;&#xA;N_sim=option.Ns;&#xD;&#xA;&#xD;&#xA;Mu=zeros(1,dim);&#xD;&#xA;Sigma=ones(1,dim);&#xD;&#xA;Samnum=100;&#xD;&#xA;Subsam=N_sim./Samnum;&#xD;&#xA;for   rv_id = 1:dim&#xD;&#xA;       X_mcs(:,rv_id) = ...&#xD;&#xA;              GenerateRV( ...&#xD;&#xA;                                   variable_table{rv_id,1}, ...&#xD;&#xA;                                   variable_table{rv_id,2}, ...&#xD;&#xA;                                   variable_table{rv_id,3}, ...&#xD;&#xA;                                   N_sim);&#xD;&#xA;end&#xD;&#xA;&#xD;&#xA;for i=1:dim&#xD;&#xA;    % Data(:,i)=unifrnd(Mu(i)-3.*Sigma(i),Mu(i)+3.*Sigma(i),N0,1);&#xD;&#xA;    Data_tiankong(:,i)=unifrnd(Mu(i)-3.*Sigma(i),Mu(i)+3.*Sigma(i),N_tianchong,1);&#xD;&#xA;end&#xD;&#xA;% load(&amp;quot;xi.mat&amp;quot;)&#xD;&#xA;Data=6.*UniformPoint(N0,dim,&#39;Latin&#39;)-3;&#xD;&#xA;xi= NatafTransformation(Data, variable_table, -1 );&#xD;&#xA;x_un= NatafTransformation(Data_tiankong, variable_table, -1 );&#xD;&#xA;for i=1:N0&#xD;&#xA;     Eva(i)=performanceFunc(xi(i,:));&#xD;&#xA;end&#xD;&#xA;PF=[];COV=[];Ncall=[];&#xD;&#xA;GKA1 = zeros(Subsam, Samnum); % 添加此行初始化&#xD;&#xA;for h=1:1000&#xD;&#xA;        theta=10*ones(1,dim); lob=1e-2*ones(1,dim); upb=20*ones(1,dim);&#xD;&#xA;        [dmodel, ~]=dacefit(xi,Eva,@regpoly1,@corrgauss,theta,lob,upb);&#xD;&#xA;        GK=@(t)predictor(t,dmodel);&#xD;&#xA;&#xD;&#xA;        [yC,or]=predictor(x_un,dmodel);&#xD;&#xA;        UC=abs((0-yC)./sqrt(or));&#xD;&#xA;   if min(UC)&amp;gt;2&#xD;&#xA;       break&#xD;&#xA;   end&#xD;&#xA;   [a,b]=find(UC==min(UC));&#xD;&#xA;   CCC=x_un(a,:);&#xD;&#xA;  x_un(a,:)=[];&#xD;&#xA;  GCe=performanceFunc(CCC);   &#xD;&#xA;  xi=[xi;CCC];&#xD;&#xA;  Eva=[Eva,GCe];&#xD;&#xA;  for j=1:Samnum&#xD;&#xA;        GKA1(:,j)=GK(X_mcs(((j-1)*Subsam+1):(j*Subsam),:));&#xD;&#xA;  end&#xD;&#xA;   GKA=GKA1(:);&#xD;&#xA;   [aa bb]=find(GKA&amp;lt;=0);&#xD;&#xA;   PF(h)=length(aa)./length(GKA);&#xD;&#xA;   COV(h)=sqrt((1-PF(h))./((N_sim-1).*PF(h)));&#xD;&#xA;   % 打印当前迭代次数和结果&#xD;&#xA;   fprintf(&#39;Iteration %d: Pf = %.6f, COV = %.6f\n&#39;, h, PF(end), COV(end));&#xD;&#xA;end&#xD;&#xA;Ncall=N0+h-1;&#xD;&#xA;fprintf(&#39;%16s%32s%32s\n&#39;,&#39;Pf_AKU&#39;, &#39;Ncall &#39;,&#39;COV&#39;)&#xD;&#xA;fprintf(&#39;%16d%30f%32f\n&#39;, PF(end), Ncall, COV(end));&#xD;&#xA;disp(&#39;----------------------------------------------------------------------------------------------------------------&#39;)&#xD;&#xA;result.Pf=PF&#xD;&#xA;result.COV=COV;&#xD;&#xA;result.Ncall=Ncall&#xD;&#xA;result.LSF=Eva(N0+1:end)&#xD;&#xA;end&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对代码做修改，计算候选样本点的[yC,or]，再通过[yC,or]计算各个样本点的目标这是一个多优化问题，求解这个问题使用gamultiobj，然后CCC是结果上的随机一个点，&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://koinin.github.io/post/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/1/01/01/</guid>
      <description>&lt;h2 id=&#34;评价标准&#34;&gt;评价标准&lt;/h2&gt;&#xA;&lt;h3 id=&#34;密封环结构安全评价准则强度准则&#34;&gt;密封环结构安全评价准则：强度准则&lt;/h3&gt;&#xA;&lt;h3 id=&#34;密封环密封性能评价准则最小接触压力准则&#34;&gt;密封环密封性能评价准则：最小接触压力准则&lt;/h3&gt;&#xA;&lt;h3 id=&#34;密封环密封性能评价准则接触均匀度准则&#34;&gt;密封环密封性能评价准则：接触均匀度准则&lt;/h3&gt;&#xA;&lt;h2 id=&#34;要解决的不确定性问题&#34;&gt;要解决的不确定性问题&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250807185917085.png&#34; alt=&#34;image-20250807185917085&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;模糊不确定性&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;随机不确定性&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;区间不确定性&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;规律&#34;&gt;规律&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;失圆度&lt;/li&gt;&#xA;&lt;li&gt;变形&lt;/li&gt;&#xA;&lt;li&gt;应力&lt;/li&gt;&#xA;&lt;li&gt;扩径到接触&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;优化方法&#34;&gt;优化方法&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250813032519789.png&#34; alt=&#34;image-20250813032519789&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250807192923570.png&#34; alt=&#34;image-20250807192923570&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;可靠性计算方法doe&#34;&gt;可靠性计算方法DOE&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 可溶桥塞金属环的表面质量、弹性模量、质量、密度、泊松比、应力参数、强度参数等材料特性参数具有不确定性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;温度对于材料力学特性也有影响&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 尺寸在规定误差范围内，因此，与几何尺寸相关的设计参数需采用区间变量来表征，几何性有不确定性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这里采用正态分布&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 载荷的大小、方向和作用点均具有不确定性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;根据已有的数据建立一个doe&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20250813191805131.png&#34; alt=&#34;image-20250813191805131&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在对金属材料进行仿真（如有限元分析 FEA），关注最大等效应力和屈服强度时，主要需要考虑以下材料性能参数：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. 弹性参数：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;弹性模量（E，杨氏模量）&lt;/strong&gt;：衡量材料在弹性阶段的刚度。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;泊松比（ν）&lt;/strong&gt;：描述材料横向变形与纵向变形的比例。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;2. 强度参数：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;屈服强度（σ&lt;sub&gt;y&lt;/sub&gt;）&lt;/strong&gt;：材料开始发生塑性变形的应力值。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;抗拉强度（σ&lt;sub&gt;max&lt;/sub&gt;）&lt;/strong&gt;（如需要，极限强度）：材料在断裂前能承受的最大应力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;3. 密度（ρ）：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果仿真涉及力学计算（如惯性、重力），则需赋予材料密度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;5. 特殊性能参数：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;断裂韧性&lt;/strong&gt;、&lt;strong&gt;疲劳强度&lt;/strong&gt;、&lt;strong&gt;剪切模量&lt;/strong&gt;等（具体取决于具体分析内容）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;材料性质基本参数&#34;&gt;材料性质基本参数：&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;参数&lt;/th&gt;&#xA;          &lt;th&gt;说明&lt;/th&gt;&#xA;          &lt;th&gt;相关性&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;弹性模量(E)&lt;/td&gt;&#xA;          &lt;td&gt;午性阶段应力-应变关系&lt;/td&gt;&#xA;          &lt;td&gt;等效应力计算必需&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;泊松比(ν)&lt;/td&gt;&#xA;          &lt;td&gt;横纵变形比例&lt;/td&gt;&#xA;          &lt;td&gt;应力状态影响&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;屈服强度(σy)&lt;/td&gt;&#xA;          &lt;td&gt;塑性区分析的临界点&lt;/td&gt;&#xA;          &lt;td&gt;判别强度极限&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;对于&lt;strong&gt;最大等效应力&lt;/strong&gt;，软件如ANSYS、Abaqus等，会根据应力和应变状态（通过输入的上述参数）进行计算。&lt;strong&gt;屈服强度&lt;/strong&gt;则用来判定材料是否已经发生塑性变形。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;strong&gt;如果是只做弹性分析&lt;/strong&gt;，上述参数基本足够；&#xA;&lt;strong&gt;如果考虑塑性行为（屈服后的变形）&lt;/strong&gt;，还应额外考虑材料的应力-应变曲线及硬化参数。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;钢材&lt;/strong&gt;常用参数：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;弹性模量：约 210 GPa&lt;/li&gt;&#xA;&lt;li&gt;泊松比：约 0.3&lt;/li&gt;&#xA;&lt;li&gt;屈服强度：Q235 约 235 MPa, Q345 约 345 MPa&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;变量不确定性量化设置&#34;&gt;变量不确定性量化设置&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;材料参数建模&#xA;钢材的材料参数通常服从正态分布（因加工/测试误差符合中心极限定理），关键参数的均值（$\mu$）和变异系数（$COV=\sigma/\mu$，衡量波动程度）如下：&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;均值\(\mu\)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;变异系数\(COV\)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;标准差\(\sigma=\mu\times COV\)&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;分布类型&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;弹性模量\(E\)&lt;/td&gt;&#xA;          &lt;td&gt;205 GPa（普通碳钢）&lt;/td&gt;&#xA;          &lt;td&gt;1%-2%（波动小）&lt;/td&gt;&#xA;          &lt;td&gt;2.05-4.1 GPa&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;泊松比\(\nu\)&lt;/td&gt;&#xA;          &lt;td&gt;0.29（钢材典型值）&lt;/td&gt;&#xA;          &lt;td&gt;1%-2%（稳定）&lt;/td&gt;&#xA;          &lt;td&gt;0.0029-0.0058&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;屈服强度\(\sigma_y\)&lt;/td&gt;&#xA;          &lt;td&gt;235 MPa（Q235）/345 MPa（Q345）&lt;/td&gt;&#xA;          &lt;td&gt;5%-10%（波动大）&lt;/td&gt;&#xA;          &lt;td&gt;11.75-23.5 MPa（Q235）/17.25-34.5 MPa（Q345）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布/韦布尔分布&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;密度\(\rho\)&lt;/td&gt;&#xA;          &lt;td&gt;7850 kg/m³（钢材）&lt;/td&gt;&#xA;          &lt;td&gt;0.1%-0.5%（极稳定）&lt;/td&gt;&#xA;          &lt;td&gt;7.85-39.25 kg/m³&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;屈服强度分布取韦布尔分布&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;几何参数建模&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;设计值&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;加工公差&lt;/strong&gt;（示例）&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;分布类型&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;分布参数&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;半径\(R\)&lt;/td&gt;&#xA;          &lt;td&gt;\(R_0=100\) mm&lt;/td&gt;&#xA;          &lt;td&gt;±0.1 mm（IT8级）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;均值\(\mu_R=R_0\)，标准差\(\sigma_R=0.1/3\approx0.033\) mm&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;密封环宽度\(H_1\)&lt;/td&gt;&#xA;          &lt;td&gt;\(H_{10}=10\) mm&lt;/td&gt;&#xA;          &lt;td&gt;±0.05 mm（IT9级）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;均值\(\mu_{H1}=H_{10}\)，标准差\(\sigma_{H1}=0.05/3\approx0.017\) mm&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;凹槽宽度\(H_2\)&lt;/td&gt;&#xA;          &lt;td&gt;\(H_{20}=8\) mm&lt;/td&gt;&#xA;          &lt;td&gt;±0.05 mm（IT9级）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;均值\(\mu_{H2}=H_{20}\)，标准差\(\sigma_{H2}=0.05/3\approx0.017\) mm&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;凹槽深度\(H_3\)&lt;/td&gt;&#xA;          &lt;td&gt;\(H_{30}=2\) mm&lt;/td&gt;&#xA;          &lt;td&gt;±0.02 mm（IT7级）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;均值\(\mu_{H3}=H_{30}\)，标准差\(\sigma_{H3}=0.02/3\approx0.0067\) mm&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;四个几何参数均值分别取54 4.8325 2 2.5&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;参数&lt;/th&gt;&#xA;          &lt;th&gt;分布类型&lt;/th&gt;&#xA;          &lt;th&gt;均值（μ）&lt;/th&gt;&#xA;          &lt;th&gt;变异系数（COV）&lt;/th&gt;&#xA;          &lt;th&gt;标准差（σ=μ×COV）&lt;/th&gt;&#xA;          &lt;th&gt;关键说明&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;弹性模量（E）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;205 GPa&lt;/td&gt;&#xA;          &lt;td&gt;2%&lt;/td&gt;&#xA;          &lt;td&gt;4.1 GPa&lt;/td&gt;&#xA;          &lt;td&gt;钢材弹性模量波动小，符合正态分布（中心极限定理）。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;泊松比（ν）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;0.29&lt;/td&gt;&#xA;          &lt;td&gt;2%&lt;/td&gt;&#xA;          &lt;td&gt;0.0058&lt;/td&gt;&#xA;          &lt;td&gt;钢材泊松比稳定，变异系数小。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;屈服强度（σᵧ）&lt;/td&gt;&#xA;          &lt;td&gt;韦布尔分布&lt;/td&gt;&#xA;          &lt;td&gt;345 MPa（目标）&lt;/td&gt;&#xA;          &lt;td&gt;5%&lt;/td&gt;&#xA;          &lt;td&gt;≈17.72 MPa&lt;/td&gt;&#xA;          &lt;td&gt;韦布尔分布更符合钢材屈服强度的&lt;strong&gt;右侧长尾&lt;/strong&gt;（偶有高屈服强度值），参数通过&lt;strong&gt;数值反推&lt;/strong&gt;得到：&lt;br&gt;形状参数\(k=27\)，尺度参数\(λ=352.1\) MPa（确保均值≈345 MPa，COV≈5%）。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;密度（ρ）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;7850 kg/m³&lt;/td&gt;&#xA;          &lt;td&gt;0.1%&lt;/td&gt;&#xA;          &lt;td&gt;7.85 kg/m³&lt;/td&gt;&#xA;          &lt;td&gt;静态仿真中&lt;strong&gt;密度不影响应力&lt;/strong&gt;（除非有重力载荷），可忽略其不确定性。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;参数&lt;/th&gt;&#xA;          &lt;th&gt;分布类型&lt;/th&gt;&#xA;          &lt;th&gt;设计均值（μ）&lt;/th&gt;&#xA;          &lt;th&gt;加工公差&lt;/th&gt;&#xA;          &lt;th&gt;标准差（σ=公差/3）&lt;/th&gt;&#xA;          &lt;th&gt;关键说明&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;密封环半径（R）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;54 mm&lt;/td&gt;&#xA;          &lt;td&gt;±1 mm（IT8级）&lt;/td&gt;&#xA;          &lt;td&gt;≈0.33 mm&lt;/td&gt;&#xA;          &lt;td&gt;正态分布的99.73%数据覆盖±3σ，故公差±Δ对应σ=Δ/3（符合加工误差规律）。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;密封环宽度（H₁）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;4.8325 mm&lt;/td&gt;&#xA;          &lt;td&gt;±0.05 mm（IT9级）&lt;/td&gt;&#xA;          &lt;td&gt;≈0.017 mm&lt;/td&gt;&#xA;          &lt;td&gt;轴向宽度，影响密封环的&lt;strong&gt;径向刚度&lt;/strong&gt;。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;凹槽宽度（H₂）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;2 mm&lt;/td&gt;&#xA;          &lt;td&gt;±0.05 mm&lt;/td&gt;&#xA;          &lt;td&gt;≈0.017 mm&lt;/td&gt;&#xA;          &lt;td&gt;凹槽的轴向长度，影响应力集中区域的&lt;strong&gt;载荷分布&lt;/strong&gt;。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;凹槽深度（H₃）&lt;/td&gt;&#xA;          &lt;td&gt;正态分布&lt;/td&gt;&#xA;          &lt;td&gt;2.5 mm&lt;/td&gt;&#xA;          &lt;td&gt;±0.02 mm（IT7级）&lt;/td&gt;&#xA;          &lt;td&gt;≈0.0067 mm&lt;/td&gt;&#xA;          &lt;td&gt;凹槽的径向深度，&lt;strong&gt;应力集中的关键因素&lt;/strong&gt;（深度越大，应力集中越明显）。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; 材料属性设置&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;80%的成功率，严重变形(10%)&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://koinin.github.io/post/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/1/01/01/</guid>
      <description>&lt;p&gt;25-07-02&#xA;郁闷的一天，感觉今年确实是本命年，诸事不顺。&lt;/p&gt;&#xA;&lt;p&gt;研究生生涯怎么这么难过啊&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;落到水里不会死，呆在水里才会死&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;25-07-03&lt;/p&gt;&#xA;&lt;p&gt;明月栞(kan)那赛高！人只要感觉自己的外表有了巨大的变化，说不定能找到自信。&lt;/p&gt;&#xA;&lt;p&gt;虽然我一直不太在乎外表，但是从这个角度来说，改变一个人的外表还是有实用性质的，好耶，我要找回自己的自信！&lt;/p&gt;&#xA;&lt;p&gt;附加一提，昨天玩的墨染希线，感觉这斗嘴好有意思啊，凉音线平平淡淡(但胜在是好基友的姐姐)，反而是四季显得中规中矩了，本来塑造的这么好的形象，结果剧情有点尬。黑皮大学生还是算了，没啥兴趣。&lt;/p&gt;&#xA;&lt;p&gt;这男主也太惨了，几次轮回全都没妈的&lt;/p&gt;&#xA;&lt;p&gt;又是转生吗，柚子社你这家伙&lt;/p&gt;&#xA;&lt;p&gt;男主真是妖怪啊(尼嘻嘻)&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://koinin.github.io/post/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/1/01/01/</guid>
      <description>&lt;p&gt;人物特点很明显啊，哈吉梦，辣妹，卧槽V，金毛，白毛大小姐(注，海豹版，眉毛都是白的)&lt;/p&gt;&#xA;&lt;h2 id=&#34;诗梦&#34;&gt;诗梦&lt;/h2&gt;&#xA;&lt;p&gt;诗梦哈气了，这种哈的最狠的，也是嗦的最用力的，哈哈:laughing:&lt;/p&gt;&#xA;&lt;p&gt;-300开局，无敌！&lt;/p&gt;&#xA;&lt;p&gt;诗梦咬钩了，我日，男主绿眼睛这么帅啊，这简直就是我&lt;/p&gt;&#xA;&lt;p&gt;坏了，我一直理解不到辣妹的感觉，现在一看，辣妹是真的能给人提供情绪价值啊&lt;/p&gt;&#xA;&lt;p&gt;五人绝景无敌了&lt;/p&gt;&#xA;&lt;p&gt;绷不住了，绘海豹，哇，还有芳乃线。为什么巫女是兼职的&lt;/p&gt;&#xA;&lt;p&gt;这才-100好感度，哈吉梦要吃金毛醋了&lt;/p&gt;&#xA;&lt;p&gt;哈吉梦老夫老妻了，不得不说，大小也是有差距的&lt;/p&gt;&#xA;&lt;p&gt;不过我感觉走辣妹线，然后找小姨子&amp;hellip;莫名的背德感，唉，太坏了，被污染了&lt;/p&gt;&#xA;&lt;p&gt;少女情怀啊&lt;/p&gt;&#xA;&lt;p&gt;不是，哈吉梦边sex，边哈气&lt;/p&gt;</description>
    </item>
    <item>
      <title>About Me</title>
      <link>https://koinin.github.io/post/1/01/01/about-me/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://koinin.github.io/post/1/01/01/about-me/</guid>
      <description>&lt;p&gt;希望好奇心能驱使一个人走到八十岁。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
