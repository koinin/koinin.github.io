<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on logn</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in Home on logn</description>
    <generator>Hugo</generator>
    <language>zh</language>
    <lastBuildDate>Tue, 17 Dec 2024 17:19:58 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PINN</title>
      <link>http://localhost:1313/post/2024/12/17/pinn/</link>
      <pubDate>Tue, 17 Dec 2024 17:19:58 +0800</pubDate>
      <guid>http://localhost:1313/post/2024/12/17/pinn/</guid>
      <description>&lt;h1 id=&#34;pinnphysics-informed-neural-networks-a-deep-learning-framework-for-solving-forward-and-inverse-problems-involving-nonlinear-partial-differential-equations&#34;&gt;PINN:Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations&lt;/h1&gt;&#xA;&lt;h2 id=&#34;基本信息&#34;&gt;基本信息&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;论文地址：https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125&lt;/p&gt;&#xA;&lt;p&gt;github:&lt;a href=&#34;https://github.com/maziarraissi/PINNs&#34;&gt;maziarraissi/PINNs: Physics Informed Deep Learning: Data-driven Solutions and Discovery of Nonlinear Partial Differential Equations&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;摘要和背景&#34;&gt;摘要和背景&lt;/h2&gt;&#xA;&lt;p&gt;我们介绍了物理信息神经网络 – 经过训练以解决监督学习任务的神经网络，同时遵守由一般非线性偏微分方程描述的任何给定物理定律。在这项工作中，我们展示了我们在解决两大类问题的背景下的发展：数据驱动的解决方案和数据驱动的偏微分方程发现。根据可用数据的性质和排列方式，我们设计了两种不同类型的算法，即&lt;em&gt;&lt;strong&gt;连续时间和离散时间模型&lt;/strong&gt;&lt;/em&gt;。第一种类型的模型形成了一个新的数据高效时空函数逼近器系列，而后一种类型允许使用具有无限阶段数的任意精确的隐式 Runge-Kutta 时间步进方案。通过流体、量子力学、反应扩散系统和非线性浅水波传播中的一系列经典问题证明了所提出的框架的有效性。&lt;/p&gt;&#xA;&lt;p&gt;随着可用数据和计算资源的爆炸性增长，最近在机器学习和数据分析方面的进展已经在各个科学领域取得了变革性的成果，包括图像识别[1]、认知科学[2]和基因组学[3]。然而，在分析复杂的物理、生物或工程系统的过程中，数据获取的成本往往是禁止性的，我们不可避免地面临着在部分信息下进行决策的挑战。在这种小数据环境下，大多数最先进的机器学习技术（例如深度/卷积/递归神经网络）缺乏鲁棒性，并且无法提供收敛性的保证。在第一眼看来，训练一个深度学习算法来准确识别一个非线性映射从几个 - 可能非常高维 - 输入和输出数据对似乎是幼稚的。幸运的是，对于许多与物理和生物系统建模有关的案例，&lt;em&gt;&lt;strong&gt;存在大量的先验知识，这些知识目前尚未在现代机器学习实践中被利用&lt;/strong&gt;&lt;/em&gt;。无论是原则上的物理定律来描述系统的时间依赖动态，还是一些实证验证的规则或其他领域的专业知识，这些先验信息都可以作为一种正则化因子来约束可接受解的空间大小（例如，在不可压缩流体动力学问题中，通过丢弃任何违反质量守恒原则的非现实流解）。作为回报，将这些结构化信息编码到学习算法中会扩大数据的信息内容，使算法能够快速找到正确的解，并且即使只有很少的训练示例也能很好地泛化。利用结构化先验信息来构造数据高效和物理信息化的学习机器的前景已经在最近的研究中得到了展示[4-6]。在那里，作者们使用高斯过程回归[7]来设计专门针对给定线性算子的函数表示，并能够准确推断解决方案并为数学物理中的几个原型问题提供不确定性估计。Raissi等人[8,9]在推断和系统识别的背景下提出了对非线性问题的扩展。尽管高斯过程在编码先验信息方面具有灵活性和数学优雅性，但处理非线性问题引入了两个重要的限制。首先，在[8,9]中，作者们必须局部线性化任何非线性项，以时间为单位，从而限制了所提方法的适用性，并损害了他们在强非线性环境中的预测准确性。其次，高斯过程回归的贝叶斯性质要求一定的先验假设，这些假设可能会限制模型的表示能力并导致鲁棒性/脆弱性问题，特别是对于非线性问题[10]。&lt;/p&gt;&#xA;&lt;h2 id=&#34;研究内容&#34;&gt;研究内容&lt;/h2&gt;&#xA;&lt;p&gt;在这项工作中，我们采用了一种不同的方法，利用深度神经网络及其作为通用函数逼近器的知名能力。在这种情况下，我们可以直接处理非线性问题，而无需进行任何先验假设、线性化或局部时间步进。我们利用自动微分的最新发展——这是科学计算中最有用但可能未充分利用的技术之一——对神经网络的输入坐标和模型参数进行微分，以获得物理信息神经网络。这些神经网络被约束为遵循源自物理定律的对称性、不变性或守恒原理，这些定律支配着通过一般时间相关和非线性偏微分方程建模的观测数据。这种简单而强大的构造使我们能够处理计算科学中的广泛问题，并引入一种潜在的变革性技术，促进新型数据高效和物理信息学习机器的发展、新类别的偏微分方程数值求解器以及模型反演和系统识别的新数据驱动方法。&lt;/p&gt;&#xA;&lt;p&gt;这项工作的总体目标是为建模和计算的新范式奠定基础，丰富深度学习与数学物理的长期发展。为此，我们的手稿分为两部分，旨在介绍我们在两类主要问题背景下的发展：数据驱动的解和数据驱动的偏微分方程发现。所有代码和数据集都可以在GitHub上获取：https://github.com/maziarraissi/PINNs。在整个工作中，我们一直使用相对简单的深度前馈神经网络架构，采用双曲正切激活函数，并且没有额外的正则化（例如，L1/L2惩罚、dropout等）。手稿中的每个数值示例都附有关于我们使用的神经网络架构的详细讨论，以及其训练过程的详细信息（例如，优化器、学习率等）。最后，附录A和附录B提供了一系列系统研究，旨在展示所提出方法的性能。&lt;/p&gt;&#xA;&lt;p&gt;在这项工作中，我们考虑参数化和非线性偏微分方程，其一般形式为&lt;/p&gt;&#xA;$$&#xA;u_t + \mathcal{N}[u ; \lambda] = 0, \, x \in \Omega, \, t \in [0, T]&#xA;$$&lt;p&gt;其中, $u(t, x)$是一个潜在解，$\mathcal{N}[\cdot, \lambda]$是由$\lambda$确定的非线性算子&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gnuradio Wsl</title>
      <link>http://localhost:1313/post/2024/12/14/gnuradio-wsl/</link>
      <pubDate>Sat, 14 Dec 2024 03:08:12 +0800</pubDate>
      <guid>http://localhost:1313/post/2024/12/14/gnuradio-wsl/</guid>
      <description>&lt;p&gt;记一个wsl安装gnuradio经历，学校有一个课是使用gnuradio玩usrp，然后建议在linux上安装，本次安装主要设计wsl上安装gnuradio。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://wiki.gnuradio.org/index.php/Main_Page&#34;&gt;GNU Radio&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;首先没得说&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;image/index/1734117151613.png&#34; alt=&#34;1734117151613&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;选择从源码构建，这里只要你是ubuntu20.04都是可以选3.10的，亲测可以装。&lt;/p&gt;&#xA;&lt;p&gt;如果IMPOERT ERROR了，大概率是LD_PATH没设置好，从源码里面构建步骤里面有具体的设置方法。&lt;/p&gt;&#xA;&lt;p&gt;装好了以后，会有一个GUI界面，会出现一个问题，如果你想设置听广播，但是wsl是没有声卡的，也就没法播放到windows, 我搜索了解决方案就一个，pulsyaudio。这软件很老了&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://research.wmz.ninja/articles/2017/11/setting-up-wsl-with-graphics-and-audio.html&#34;&gt;Setting Up WSL with Graphics and Audio - Mianzhi Wang&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;而且每次启动都很麻烦，你需要找到busid,然后共享，分享给wsl（因为wsl默认是不支持usb的，你需要把usrp分享给wsl他才能读取）, 然后打开pulsyaudio。&lt;/p&gt;&#xA;&lt;p&gt;所以权衡之下，只做此记录，转向双系统，随便划100g硬盘给ubuntu就行，而且感觉原生linux编译快了很多有没有，ubuntu还没有windows这里的合盖休眠问题，合盖后每次启动都很快。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DataMining</title>
      <link>http://localhost:1313/post/2024/12/10/datamining/</link>
      <pubDate>Tue, 10 Dec 2024 19:17:52 +0800</pubDate>
      <guid>http://localhost:1313/post/2024/12/10/datamining/</guid>
      <description>&lt;h1 id=&#34;第一章&#34;&gt;第一章&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;这份PPT的内容是关于“大数据分析与挖掘”的课程介绍，由Junming Shao教授主讲。以下是PPT内容的整理和知识点概述，以及一些适当的扩展来帮助你理解记忆：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-课程信息&#34;&gt;1. 课程信息&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;讲师&lt;/strong&gt;：Junming Shao&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;课程网站&lt;/strong&gt;：dm.uestc.edu.cn&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;教材&lt;/strong&gt;：《Mining of Massive Datasets》和《Data Mining：Concept and Techniques》&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;在线公开课&lt;/strong&gt;：包括“Mining of Massive Datasets”和“Machine Learning”（Andrew Ng）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-课程内容&#34;&gt;2. 课程内容&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;大数据分析入门&lt;/strong&gt;（Lixin Duan）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据挖掘基础&lt;/strong&gt;（Lixin Duan）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;哈希技术&lt;/strong&gt;（Lixin Duan）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;抽样技术&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据流挖掘&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;图挖掘&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hadoop-Spark技术&lt;/strong&gt;（Junming Shao）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;自然语言处理/语言模型&lt;/strong&gt;（Ke Qin）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-先修知识&#34;&gt;3. 先修知识&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;基础算法&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;概率与统计&lt;/strong&gt;（包括概率、贝叶斯等）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;线性代数&lt;/strong&gt;（矩阵理论）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;编程&lt;/strong&gt;（Java/C++/Python等）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据库系统&lt;/strong&gt;（SQL、关系数据库）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-课堂期望&#34;&gt;4. 课堂期望&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;遵守课堂规则&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;尽最大努力参与课堂活动、作业和测试&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-评估方式&#34;&gt;5. 评估方式&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;深入报告&lt;/strong&gt;：占40%&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;课堂活动&lt;/strong&gt;：占10%&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;闭卷期末考试&lt;/strong&gt;：占50%&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-大数据时代&#34;&gt;6. 大数据时代&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;我们生活在哪个时代？&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;大数据在各领域的应用&lt;/strong&gt;：媒体/娱乐、医疗保健、工业、电子商务等&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;大数据的例子&lt;/strong&gt;：Flickr、YouTube、Web视频观看、数字照片、Yahoo! Webmap、人类基因组等&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-大数据的推动因素&#34;&gt;7. 大数据的推动因素&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据存储&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;计算能力&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据可用性&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-大数据的定义和特征&#34;&gt;8. 大数据的定义和特征&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：大数据是指难以使用传统数据库和软件技术处理的大量结构化和非结构化数据。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：通常被称为4V（Volume、Velocity、Variety、Veracity）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-数据挖掘的历史和发展&#34;&gt;9. 数据挖掘的历史和发展&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;1989年IJCAI工作坊&lt;/strong&gt;：知识发现在数据库中&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1991-1994年&lt;/strong&gt;：知识发现在数据库的工作坊&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1995-1998年&lt;/strong&gt;：知识发现在数据库和数据挖掘的国际会议（KDD’95-98）&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1997年&lt;/strong&gt;：数据挖掘和知识发现杂志&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-数据挖掘的潜在应用&#34;&gt;10. 数据挖掘的潜在应用&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;市场分析与管理&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;企业分析与风险管理&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;欺诈检测与挖掘异常模式&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-数据挖掘的主要任务&#34;&gt;11. 数据挖掘的主要任务&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;关联规则挖掘&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;聚类分析&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;分类/预测&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;异常检测&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-大数据挖掘的主要方向&#34;&gt;12. 大数据挖掘的主要方向&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;规模（Volume）&lt;/strong&gt;：可扩展的数据挖掘算法&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;速度（Velocity）&lt;/strong&gt;：数据流挖掘&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;多样性（Variety）&lt;/strong&gt;：多源或多类型数据挖掘&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;真实性（Veracity）&lt;/strong&gt;：不确定性分析、链接/缺失值预测&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;13-相关材料&#34;&gt;13. 相关材料&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;主要数据挖掘会议&lt;/strong&gt;：ACM SIGKDD、IEEE ICDM、SIAM SDM等&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;主要数据挖掘期刊&lt;/strong&gt;：IEEE Transactions on Knowledge and Data Engineering (TKDE)、SIGKDD Explorations等&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;这份PPT提供了大数据分析与挖掘课程的全面概览，包括课程内容、先修知识、评估方式、大数据的定义和特征、数据挖掘的历史和发展、潜在应用、主要任务以及大数据挖掘的主要方向。通过这些知识点，你可以对大数据分析与挖掘有一个系统的认识，并了解其在现代技术和社会中的重要性。&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>NextWebConflict</title>
      <link>http://localhost:1313/post/2024/12/09/nextwebconflict/</link>
      <pubDate>Mon, 09 Dec 2024 20:55:15 +0800</pubDate>
      <guid>http://localhost:1313/post/2024/12/09/nextwebconflict/</guid>
      <description>&lt;p&gt;记录一个遇到的名称冲突问题，使用one-api作为api管理的时候，如果要使用claude的模型，但是chatgptnextweb已经内置了claude的模型名称，会引发冲突，所以可以在custom models中加入：&lt;/p&gt;&#xA;&lt;p&gt;+claude-3-5-sonnet-20241022@OpenAI=claude-3-5-sonnet-20241022&lt;/p&gt;&#xA;&lt;p&gt;注意，还支持扩展用法，以下就是隐藏了所有模型，然后增加了claude, gemini，当然这里的gemini还是走的默认的google接口，而claude走的OpenAI的接口（也就是我们oneapi的接口）：&lt;/p&gt;&#xA;&lt;p&gt;-all,+gemini-1.5-flash,+claude-3-5-sonnet-20241022@OpenAI=claude-3-5-sonnet-20241022&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM_batch_reference</title>
      <link>http://localhost:1313/post/2024/12/06/llm_batch_reference/</link>
      <pubDate>Fri, 06 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/12/06/llm_batch_reference/</guid>
      <description>&lt;p&gt;[toc]&lt;/p&gt;&#xA;&lt;h1 id=&#34;llama-31-70b的部署和批量推理离线推理&#34;&gt;Llama-3.1-70b的部署和批量推理（离线推理）&lt;/h1&gt;&#xA;&lt;p&gt;offline inferencem, or batch inference&lt;/p&gt;&#xA;&lt;h3 id=&#34;top_p-vs-top_k&#34;&gt;top_p vs top_k&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;code&gt;top_p&lt;/code&gt;是指在生成文本时，选择概率最高的 &lt;code&gt;p&lt;/code&gt;个token作为候选集。例如，如果 &lt;code&gt;top_p&lt;/code&gt;为0.9，则意味着在生成文本时，选择概率最高的90%的token作为候选集。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;top_p&lt;/code&gt;的作用是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;限制生成的文本的多样性：通过选择概率最高的token，&lt;code&gt;top_p&lt;/code&gt;可以限制生成的文本的多样性，使得生成的文本更加集中和可预测。&lt;/li&gt;&#xA;&lt;li&gt;提高生成的文本的质量：通过选择概率最高的token，&lt;code&gt;top_p&lt;/code&gt;可以提高生成的文本的质量，使得生成的文本更加流畅和自然。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;top_k&lt;/code&gt;是指在生成文本时，选择前 &lt;code&gt;k&lt;/code&gt;个概率最高的token作为候选集。例如，如果 &lt;code&gt;top_k&lt;/code&gt;为100，则意味着在生成文本时，选择前100个概率最高的token作为候选集。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;top_k&lt;/code&gt;的作用是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提高生成的文本的多样性：通过选择前 &lt;code&gt;k&lt;/code&gt;个概率最高的token，&lt;code&gt;top_k&lt;/code&gt;可以提高生成的文本的多样性，使得生成的文本更加丰富和多样。&lt;/li&gt;&#xA;&lt;li&gt;降低生成的文本的质量：通过选择前 &lt;code&gt;k&lt;/code&gt;个概率最高的token，&lt;code&gt;top_k&lt;/code&gt;可以降低生成的文本的质量，使得生成的文本更加随机和不确定。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;top_p&lt;/code&gt;和 &lt;code&gt;top_k&lt;/code&gt;是两个相关但不同的参数。&lt;code&gt;top_p&lt;/code&gt;限制了生成的文本的多样性，而 &lt;code&gt;top_k&lt;/code&gt;提高了生成的文本的多样性。通常情况下，&lt;code&gt;top_p&lt;/code&gt;和 &lt;code&gt;top_k&lt;/code&gt;会被同时使用，以便在生成的文本的质量和多样性之间找到一个平衡。&lt;/p&gt;&#xA;&lt;p&gt;例如，如果你想生成一个高质量的文本，你可以设置 &lt;code&gt;top_p&lt;/code&gt;为0.9和 &lt;code&gt;top_k&lt;/code&gt;为100。这意味着在生成avour时，选择概率最高的90%的token作为候选集，并从候选集中选择前100个概率最高的token作为生成的文本。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;huggingface-model&#34;&gt;Huggingface model&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;huggingface-cli login&#xD;&#xA;huggingface-cli download -h&#xD;&#xA;huggingface-cli download meta-llama/Llama-3.1-70B-Instruct&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;vllm&#34;&gt;Vllm&lt;/h2&gt;&#xA;&lt;h3 id=&#34;cuda和pytorch&#34;&gt;CUDA和Pytorch&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/null_one/article/details/129412159&#34;&gt;显卡驱动CUDA 和 pytorch CUDA 之间的区别_cuda版本和torch.cuda一样吗-CSDN博客&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;区别了nvcc nvidia-smi torch.__version__&lt;/p&gt;&#xA;&lt;h3 id=&#34;conda和pip&#34;&gt;conda和pip&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/Li-JT/p/14024034.html&#34;&gt;conda install和pip install区别 - lmqljt - 博客园&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;pip 包含build conda一般是可执行&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;安装环境 此处安装的是老版vllm 支持cuda11.8&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;# conda 虚拟环境&#xD;&#xA;conda create myenv&#xD;&#xA;&#xD;&#xA;# 先安装pytorch&#xD;&#xA;conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia&#xD;&#xA;&#xD;&#xA;# Install vLLM with CUDA 11.8.&#xD;&#xA;export VLLM_VERSION=0.6.1.post1&#xD;&#xA;export PYTHON_VERSION=310&#xD;&#xA;pip install https://github.com/vllm-project/vllm/releases/download/v${VLLM_VERSION}/vllm-${VLLM_VERSION}+cu118-cp${PYTHON_VERSION}-cp${PYTHON_VERSION}-manylinux1_x86_64.whl --extra-index-url https://download.pytorch.org/whl/cu11&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;代码&#xA;注意这里的要指定 &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;， 而且在代码内支持着一种方式&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/m0_65814643/article/details/143882882&#34;&gt;【杂记】vLLM如何指定GPU单卡离线推理_vllm指定gpu-CSDN博客&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>RalativePath</title>
      <link>http://localhost:1313/post/2024/11/18/ralativepath/</link>
      <pubDate>Mon, 18 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/11/18/ralativepath/</guid>
      <description>&lt;p&gt;一般来说，我们写markdown的图片都是存储在index.md同目录下的assets/文件夹里面，但是hugo不能识别到这个文件夹，所以我们在写markdown的时候需要创建一个文件夹，such as:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;RelativePath/&#xA;    assets/&#xA;    imdex.md&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;$$x_{x+1}$$</description>
    </item>
    <item>
      <title>Text2cad</title>
      <link>http://localhost:1313/post/2024/11/17/text2cad/</link>
      <pubDate>Sun, 17 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/11/17/text2cad/</guid>
      <description>&lt;h1 id=&#34;基本信息&#34;&gt;基本信息&lt;/h1&gt;&#xA;&lt;p&gt;论文地址：http://arxiv.org/abs/2409.17106&#xA;repository: &lt;a href=&#34;https://sadilkhan.github.io/text2cad-project/&#34;&gt;https://sadilkhan.github.io/text2cad-project/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;摘要与背景&#34;&gt;摘要与背景&lt;/h1&gt;&#xA;&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;&#xA;&lt;p&gt;在现代软件中制作复杂的计算机辅助设计 (CAD) 模型原型可能非常耗时。这是由于缺乏能够快速生成更简单的中间零件的智能系统。我们提出了 Text2CAD，这是第一个使用适合所有技能水平的设计师友好指令生成文本到参数 CAD 模型的 AI 框架。此外，我们引入了一个数据注释管道，用于使用 Mistral 和 LLaVA-NeXT 根据 DeepCAD 数据集的自然语言指令生成文本提示。该数据集包含 ~ 170K 个模型和 ~ 660K 个文本注释，从抽象 CAD 描述（例如，生成两个同心圆柱体）到详细规范（例如，绘制两个以 (x, y) 为中心、半径为 r1、r2 的圆，并沿d 后正常&amp;hellip;）。在 Text2CAD 框架内，我们提出了一种基于端到端 Transformer 的自回归网络，用于从输入文本生成参数化 CAD 模型。我们通过多种指标来评估模型的性能，包括视觉质量、参数精度和几何精度。我们提出的框架在人工智能辅助设计应用中显示出巨大的潜力。项目页面位于 &lt;a href=&#34;https://sadilkhan.github.io/text2cad-project/&#34;&gt;https://sadilkhan.github.io/text2cad-project/&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;可以将其结合设计，为中间件模型创建文本提示（零件和参数），可以方便搜索&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;创新点&#34;&gt;创新点&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;作为第一个使用文本描述生成参数化 3D CAD 模型的 AI 框架&lt;/li&gt;&#xA;&lt;li&gt;提出了一个数据注释管道，它利用LLM 和VLM 生成一个数据集，其中包含具有不同复杂程度和参数细节的文本提示&lt;/li&gt;&#xA;&lt;li&gt;提出了一种基于端到端 Transformer 的自回归架构，用于根据输入文本提示生成 CAD 设计历史记录。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;研究内容&#34;&gt;研究内容&lt;/h1&gt;&#xA;&lt;h2 id=&#34;算法定义&#34;&gt;算法定义&lt;/h2&gt;&#xA;&lt;h3 id=&#34;text2cad数据标注&#34;&gt;Text2CAD数据标注&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/image-20241117232131281.png&#34; alt=&#34;image-20241117232131281&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;使用vllm进行形状描述&lt;/p&gt;&#xA;&lt;p&gt;首先从预定的摄像机角度为每个单独的零件和最终的 CAD 模型生成多视图图像。然后，这些图像在 LLaVANeXT [25] 模型的预定义提示&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多层级设计架构&lt;/p&gt;&#xA;&lt;p&gt;DeepCAD [55] 数据集包含 JSON 格式的 CAD 构造序列。我们首先使用“最小元数据生成器”对原始 CAD 构造序列进行预处理，该生成器用更有意义的术语（例如“part_1”、“loop_1”）替换随机、无意义的键。&lt;/p&gt;</description>
    </item>
    <item>
      <title>记录一次zsh配置流程</title>
      <link>http://localhost:1313/post/2024/11/03/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1zsh%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Sun, 03 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/11/03/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1zsh%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;记录一次zsh配置流程（zsh + oh my zsh）&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;DD系统&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/bin456789/reinstall&#34;&gt;https://github.com/bin456789/reinstall&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;安装zsh&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code&gt;apt install zsh -y&#xD;&#xA;chsh -s /bin/zsh&#xD;&#xA;# reboot&#xD;&#xA;&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;安装 OMZ&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code&gt;sh -c &amp;quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&amp;quot;&#xD;&#xA;&#xD;&#xA;# 配置文件&#xD;&#xA;~/.zshrc&#xD;&#xA;&#xD;&#xA;# 插件&#xD;&#xA;~/.oh-my-zsh/custom/plugins&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Mamba2 pre-trained model使用</title>
      <link>http://localhost:1313/post/2024/08/12/mamba2-pre-trained-model%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/08/12/mamba2-pre-trained-model%E4%BD%BF%E7%94%A8/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;参考 &lt;a href=&#34;https://github.com/vasqu/mamba2-torch&#34;&gt;https://github.com/vasqu/mamba2-torch&lt;/a&gt; &amp;gt; &lt;a href=&#34;https://huggingface.co/AntonV/mamba2-130m-av&#34;&gt;https://huggingface.co/AntonV/mamba2-130m-av&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;这里用的是作者自己转换的mamba2参数模型（从原始版本转换成hf的transfromer兼容版本），并提供了一个本地包，但是安装包的时候出现一点问题，版本不符合 需要把requirements.txt中的torch triton==2.2.0 改成你现在的版本，我测试没什么问题&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux terminal 美化</title>
      <link>http://localhost:1313/post/2024/08/11/linux-terminal-%E7%BE%8E%E5%8C%96/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/08/11/linux-terminal-%E7%BE%8E%E5%8C%96/</guid>
      <description>&lt;p&gt;通过.bashrc美化shell&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;PS1=&amp;quot;\[\\\[\\e\[01;37m\\\]\\t\]\[\\\[\\e\[01;32m\\\]\\u\\\[\\e\[37m\\\]@\\h \\\[\\e\[36m\\\]\\w\\\[\\e\[m\\\]\]\\\\$ &amp;quot; &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;通过.vimrc美化vim&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;syntax on &amp;quot; 设置语法高亮 &#xA;set nocompatible&#xA;set nu &amp;quot; 设置行数显示 &#xA;set tabstop=4 &amp;quot; 设置tab缩进长度为4空格 &#xA;set autoindent &amp;quot; 设置自动缩进，适用所有类型文件 &#xA;set cindent &amp;quot; 针对C语言的自动缩进功能，在C语言的编程环境中，比autoindent更加精准 &#xA;set list lcs=tab:\\|\\ &amp;quot; 设置tab提示符号为 &amp;quot;|&amp;quot;，注意最后一个反斜杠后面要留有空格 &#xA;set cc=0 &amp;quot; 设置高亮的列，这里设置为0，代表关闭 set cursorline &amp;quot; 突出显示当前行 &#xA;set showmode &#xA;set showcmd &#xA;set mouse =a &#xA;set t_Co=256 &#xA;set relativenumber &#xA;set noerrorbells &#xA;set vb t_vb=&#xA;set encoding=utf-8 &#xA;set termencoding=utf-8&#xA;&#xA;set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr &#xA;set fileencoding=utf-8 &#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>极乐迪斯科（Disco Elysium）游玩体验</title>
      <link>http://localhost:1313/post/2024/08/10/%E6%9E%81%E4%B9%90%E8%BF%AA%E6%96%AF%E7%A7%91disco-elysium%E6%B8%B8%E7%8E%A9%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Sat, 10 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/08/10/%E6%9E%81%E4%B9%90%E8%BF%AA%E6%96%AF%E7%A7%91disco-elysium%E6%B8%B8%E7%8E%A9%E4%BD%93%E9%AA%8C/</guid>
      <description>&lt;h2 id=&#34;极乐迪斯科disco-elysium游玩体验&#34;&gt;极乐迪斯科（Disco Elysium）游玩体验&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;写于2024-08-10 游戏时长18.9h&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;很诚挚的定论她，这是我开始玩单机以来，第一部不会感到倦怠的作品。每一次剧情推动，都认真的考虑剧情的走向，每一个角色都是下了大功夫的塑造关系，性格，寓意。伏笔从始至终，不是工业化流水线，甚至旁白都是大量的配音，沉浸到思维的碰撞中。不得不过，要翻译这样一部作品是很困难的，各类思维的表达方式不同，文本前后联系。对这样的一部作品我觉得是有必要探讨他的寓意的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;diving-into-disco&#34;&gt;diving into Disco&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;你可以随意向市民们提问，人们总是对拥有权力的人保持宽容，特别是你警官。 &amp;gt; &amp;gt; 非原话&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Disco是什么？一切从Disco，酒精，毒品，性爱开始，你分配的每一个技能点数，都与政治立场无关，只决定你和人的交流进展。正如马哲说，人的存在就是人的社会关系。我们所熟知的领袖，也只不过在其中某些点数过于常人。当然，玩家无所不能，一次又一次的骰子掷下，我们开始逐渐进入这个城市。这个故事发生的城市很小，不过麻雀虽小，却包含一个港口，公路要塞，小岛，教堂，渔村。&lt;/p&gt;&#xA;&lt;p&gt;一个灵魂从一个腐朽的身体里诞生了，你，失忆了。这个城市看起来很不友好，康米主义分子，极端种族主义，极端自由主义，中立派相互对立。而这样一片土地曾经发生过什么呢，君主专制，大革命，大革命的失败，无政府，自由主义，无数制度都存在过这篇土地，都留下过自己的痕迹。&lt;/p&gt;&#xA;&lt;p&gt;竹节虫是什么，逃兵是什么，为什么逃兵看不到竹节虫，为什么又要嫉妒那个吊人和女人，为什么他要偷窥女人，为什么他要威胁女人，为什么坤诺表现得如何疯狂，为什么工会如此排外，为什么不同的人格都出现在同一具腐朽的身体里，警察是什么，我是谁?&lt;/p&gt;&#xA;&lt;p&gt;当资本主义和人民分手，本来曾经康米内在化的我将如何面对这个矛盾重重的世界？&lt;/p&gt;</description>
    </item>
    <item>
      <title>明末·饿殍千里行游戏体验</title>
      <link>http://localhost:1313/post/2024/08/07/%E6%98%8E%E6%9C%AB%E9%A5%BF%E6%AE%8D%E5%8D%83%E9%87%8C%E8%A1%8C%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/08/07/%E6%98%8E%E6%9C%AB%E9%A5%BF%E6%AE%8D%E5%8D%83%E9%87%8C%E8%A1%8C%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;2024-08-07 &amp;gt; 啊哈哈，最近高强度游戏，游戏体验出的太快了，我写体验，就不能只体验，会随着时间写我的一些吐槽把&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;看到那个“安”字，不知道为什么想起了盗官记。就想写一个盗官记改编，希望不是废案吧。零创产量挺高的啊，最近出这么多游戏，暗黑桃花源其实不错，画风也不错，有Raging loop的味道。那个二分之一画风差距巨大，我其实更喜欢黑色阵营，不过游戏太难玩&amp;hellip;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;阿巴阿巴阿巴~&lt;/p&gt;&#xA;&lt;p&gt;挺平淡的展开，作画有好有坏，经费都花在了该花的地方是吧（笑~）。&lt;/p&gt;&#xA;&lt;p&gt;怎么和带小孩一样&amp;hellip;Hanser配音还是很出戏啊，明显在藏刀啊，舌头挺正常一个人。开始的令牌感觉有伏笔。故事太短，总感觉人物刻画不够。&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;卖给身边不愁吃喝的亲友&amp;rdquo;。我要是有亲友还至于干这行吗（笑。&lt;/p&gt;&#xA;&lt;p&gt;穗穗这家世够惨的，其实选明朝还挺合适的，毕竟王爷多。穗穗这后面的剧情&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;其实你单单要写，完全可以把两件事拆开，对穗穗的感情混杂着对王侯将相的愤慨，显得主次不清，没有感觉悲壮。倒是李自成的形象挺帅的，又来一个想当皇帝的。&lt;/p&gt;&#xA;&lt;p&gt;总之全篇我最有印象的还是穗穗有多惨，而这不过是一个王朝末期的剪影而已。&lt;/p&gt;&#xA;&lt;p&gt;最后，仅以此篇献给所有动手实现”不再有饿殍“的人&lt;/p&gt;&#xA;&lt;p&gt;剧情一般，打分的话，3.1/5&lt;/p&gt;</description>
    </item>
    <item>
      <title>Steins;Gate 游戏体验</title>
      <link>http://localhost:1313/post/2024/08/06/steinsgate-%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/08/06/steinsgate-%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;2024-08-06&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;确实是一部很慢热的游戏，剧情前一半多都是日常，直到SERN破门而入我还以为是凶真的幻想，自此剧情开始突然黑残深，我当然想要挽回铃羽啊，可是世界的惯性决定，胸针如果不想牺牲什么。是达不到目的的，从男主收到那条短信开始，命运已经决定了，你不是在拯救，你是去换，到最后还剩下了什么呢？记忆太多会改变一个人的，当一个人不把记忆当回事的时候，就容易崩坏了。 桶子真男人，不愧有个这么好的女儿。红莉栖确实是助手，和胸针一唱一和，主打一个反差萌。铃羽最后的一年太让人心疼了。 PS，布朗管女儿的那张原画是真的吓人&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;菲莉丝结局，放弃了时间机器，SERN也没上门。 所以一开始使用时间机器直接或者间接的导致了后面的IBN消失，胸针只不过现在走着一条修正时间线的路，既然如此，直接回到最初，拒绝时间机器的诱惑。 直接让他爸以IBN作为赎金给神社，岂不是美哉！（~~~我是天才~~~） 怪不得菲莉丝之前一直赢，原来是读心术&amp;hellip;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;秀吉啊，秀吉 唉，老是搞这种约会，离别的时候怎么放得下嘛，你看摄影小子就不专业，男的不是更好？！微小的调整是修改不了时间线的，不要有这样的想法。 游戏完全参照了设定，其实是线性的叙事结构，所有的结局都是分支结局，虽然并不完美。 还是没法接受&amp;hellip;人命换性别？你已经牺牲了两个人的希望了，为什么半路放弃了。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;谁都可以牺牲，一切为了真由里 2. 回到最初，从头开始！已经赎完了所有的罪，我们选择最后的结局。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;其实在理论方面有所不完善，但是只要用时间是完全线性就可以解释，如果是我来写，原来的β时间线因为助手死了，所以男主跳跃到了其他时间线，而本来的β时间线停滞了，这时候，胸针是不知道死没死的，而胸针穿越回来后的β时间线，因为此时的胸针记忆和之前不同其实不是原本的时间线，然后经过十年的计算和研究，找到了肉身穿越的方法，但是由于主角团都不能和现在的自己碰面，所以只能由桶子的女儿来传信和救出重伤的胸针，不然胸针如果死了，蝴蝶效应又会产生，胸针要做到少改变状态的同时，还能通过这个时间黑盒得到自己想要的结果。所以拯救助手的是记忆，从一开始就已经确定了的记忆。&lt;/p&gt;&#xA;&lt;p&gt;理论不是很严谨，但是内容确实很催泪，一次又一次的放弃，只为了最后能救回助手。顺便一提，出生父亲。&lt;/p&gt;</description>
    </item>
    <item>
      <title>记录一次服务器跑大模型经历</title>
      <link>http://localhost:1313/post/2024/07/31/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B7%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%8F%E5%8E%86/</link>
      <pubDate>Wed, 31 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/07/31/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B7%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%8F%E5%8E%86/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;由于网络问题，速度慢或者无法直连hugging-face docker hub pipy&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;设置系统代理&#34;&gt;设置系统代理&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;# set proxy config via profie.d - should apply for all users &#xA;export http_proxy=&amp;quot;http://127.0.0.1:10000/&amp;quot; &#xA;export https_proxy=&amp;quot;http://127.0.0.1:10000/&amp;quot; localhost&amp;quot;&#xA;&#xA;# 注意，jupyter是不会直接调用你的bash设置的，所以你需要在cell先设置一下系统代理，这样jupyter笔记本就会调用你的代理了&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;pipy-使用国内镜像我用的清华镜像也可以用其他的&#34;&gt;Pipy 使用国内镜像，我用的清华镜像，也可以用其他的&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;# pipy 如果你配置了代理，就可以不用设置这个源了&#xA;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;docker-主要是连接docker-hub-比较吃力-可以选1panel的镜像&#34;&gt;Docker 主要是连接docker hub 比较吃力 可以选1panel的镜像&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39; { &amp;quot;registry-mirrors&amp;quot;: \[ &amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;, &amp;quot;https://docker.nju.edu.cn&amp;quot;, docker.1panel.live \] } EOF sudo systemctl daemon-reload sudo systemctl restart docker &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;深度学习环境配置-这里有两种方案--方案一-只有pytorchjupyter--refer---httpshubdockercomrtverouspytorch-notebook&#34;&gt;深度学习环境配置 这里有两种方案 #### 方案一-只有pytorch+jupyter &amp;gt; refer -&amp;gt; &lt;a href=&#34;https://hub.docker.com/r/tverous/pytorch-notebook&#34;&gt;https://hub.docker.com/r/tverous/pytorch-notebook&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;这里面是没有nvcc的需要在以下网站里安装 &amp;gt; refer -&amp;gt; &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads&#34;&gt;https://developer.nvidia.com/cuda-downloads&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>有关White album2一点点想法</title>
      <link>http://localhost:1313/post/2024/07/28/%E6%9C%89%E5%85%B3white-album2%E4%B8%80%E7%82%B9%E7%82%B9%E6%83%B3%E6%B3%95/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/07/28/%E6%9C%89%E5%85%B3white-album2%E4%B8%80%E7%82%B9%E7%82%B9%E6%83%B3%E6%B3%95/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;和纱，你说我是不是真的坏掉了呢？&#xA;小木曾雪菜&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;关于白色相簿2&#34;&gt;关于白色相簿2&lt;/h2&gt;&#xA;&lt;p&gt;作为游玩的比较晚的玩家，其实一起很好奇为什么这么多人是所谓的白学家，怎样一个作品才能在玩家群体引起这样的风波，在几十个小时的心理折磨后，终于写下了这篇观后感，我会尝试用一点诙谐的感觉写出我记忆里的观后感。 白2总共大致分为三部，没有选择的少年时期，遇得到的人都是上天已经注定好的；因为年少时犯的错，没有做到的事导致的青年；往事开始回首的晚年，是坚持本心还是走向崩坏。 故事的起点就是我人生遗憾的起点，我年轻的时候啊，也有一个闲暇时飘出钢琴声的音乐教室呢，放学那天我和朋友说，嘿，你知道吗，那个妹子，我一定要拿下。友人A说，你还是先把对线拿下，别玩你那b卡牌了，卡牌没出路的。我反驳，我卡牌猛地一，不信solo?友人B补充，走走，这周末我带你们乱杀。我一直很自信自己的卡牌大师，裁决第一AD打野卡牌，这么多前缀是我自信的本钱。&lt;/p&gt;&#xA;&lt;h3 id=&#34;关于冬马和纱&#34;&gt;关于冬马和纱&lt;/h3&gt;&#xA;&lt;p&gt;一个记忆里高冷的女孩子，哪怕你的时光飞逝，她总是驻足在那样一间音乐室里，音乐室只不过一个黑衣女孩和一架钢琴而已，而已。换做后来的我，还愿意去打开这样的一扇门吗，还愿意承担这样的独特的记忆吗？ 这样一个女孩子怎么能喜欢上我呢？首先你得有自己的闪耀点吧，当天晚上我挑灯夜战，终于研究出了一套打野的秘籍，怂。朋友们看我总是不离开野区恨得牙痒痒，我告诉他们，等我刷出来，就能翻盘，你们先顶住，我继续去折腾我的吞噬者打野刀。或许我有一点点天赋，只不过稍微努力，就拿到了班上的第二名，成绩就是年轻的我的装逼本钱。我自感觉自己有了追她的资本，就开始怂恿我的朋友们帮我追她。 只不过感情这个事情，说来简单，谁也不知道是怎么来的。只不过我的故事就此而结束了，没有下一节，年少的轻狂最终只是遗憾，看似若即若离的关系，同样伴随着升学，两个人走向了背向。 我其实不知道那时的我是怎样的一个位置，是不是在她心里也有一席之地，哪怕现在的我也会回答不聊这个问题。 她是我的人生之光，普罗米修斯偷盗来的宙斯之火，冬-马-和-纱，这样随意的几个词的简单组合，却是像是伴随人类之火的潘多拉魔盒，美丽而致命，也让我的心遭受日晒雨淋。 就像选择了和纱一样，我享受了内心的满足，却只能接受这个内心容器的拷打，哪怕这时候的我再幸福，终究终究灾难在这片大地留下的是千沟万壑。&lt;/p&gt;&#xA;&lt;h3 id=&#34;关于小木曾雪菜&#34;&gt;关于小木曾雪菜&lt;/h3&gt;&#xA;&lt;p&gt;IC篇幅其实已经把雪菜勾绘出一个大概了，闪光的外表下其实也是有着自己小孩子的一面，她看似和谁都很好，但是却是和谁都疏远，也只有一个心细的男生能找到她内心的弱点。但是那个下雪的夜晚彻底让三个人的命运走向了渐行渐远的方向。 我的内心是守序善良的，所以我选择救赎雪菜，也是救赎我因为自己的错误而让她失去的三年，我已经伤害过她一次了，又怎么能伤害她。这不仅是一种弥补，也是一种救赎，放下了曾经的自己，认识到自己的幼稚。这三年我常常会想，我是不是错了了什么，当时如果我坚持是不是结构又会不一样呢，是不是我还有哪里做的不好。 爱是一种陪伴，或许可以解释为一种习惯，当我习惯了一个人，她总是能接受我，哪怕我选择了背叛，哪怕我选择了说谎，哪怕我在两个人之中痛苦而快乐。一个你永远可以回到的家，这或许是我，这样一个没有家庭的我真正想要的。 那么多的世界线，她总是陪在我身边，没有一次例外，她甚至愿意分享爱，三个人的爱。&lt;/p&gt;&#xA;&lt;h3 id=&#34;关于和泉千晶&#34;&gt;关于和泉千晶&lt;/h3&gt;&#xA;&lt;p&gt;这是最后一个角色了，她的出现很突兀，结束了我痛苦的游戏时长，在她身边，我可以不去在乎是不是伤害到雪菜，在他身边，我可以忘掉和纱，只有在他身边，我才可以接受我自己的软弱，正视我曾经犯下的错误。 我很轻松，她的生命需要我，我也需要她，直到某天，她消失了。 雪菜是多么好啊，她总是能接受如何的我，即使我不断地去伤害她，即使我在无数选择中错过了她。和纱是多么好啊，年少时的爱是多么难得，年少时的遗憾又是多么意难平。 很可惜，我的人生没有这样的一个人来救赎我，是我不配得到这样的爱意，这样参杂着利用和真挚的爱意。千晶的爱纯粹吗？我想不是的，那又怎么样呢，爱又何必纯粹，人也太复杂了。&lt;/p&gt;&#xA;&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;就快了，就快了啊&#xA;和泉千晶&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;我喜欢雪菜，我喜欢和纱，两个人我都只能选择伤害。人生其实少年就死了，只不过晚年才开始赎罪。&lt;/p&gt;</description>
    </item>
    <item>
      <title>有关魔法使之夜</title>
      <link>http://localhost:1313/post/2024/07/28/%E6%9C%89%E5%85%B3%E9%AD%94%E6%B3%95%E4%BD%BF%E4%B9%8B%E5%A4%9C/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/07/28/%E6%9C%89%E5%85%B3%E9%AD%94%E6%B3%95%E4%BD%BF%E4%B9%8B%E5%A4%9C/</guid>
      <description>&lt;h2 id=&#34;魔法使之夜&#34;&gt;魔法使之夜&lt;/h2&gt;&#xA;&lt;p&gt;某种程度上是我的型月的入门作(空之境界很早之前看的，但是没看懂)，你要说感动，更多的是产生了不少好奇对这样一个故事的背景。 对两位女主角的描述，我更愿意称其为魔女之夜(笑 其实作品主要还是战斗，真正做到了文字描述战斗的极限，配合动图。 红发青子点燃了我的战斗之魂，不愧是第五魔法使。 所以，魔法使背后的世界，是怎么样的呢？ 逐渐走入Fate的大坑了呢&lt;/p&gt;</description>
    </item>
    <item>
      <title>关于摄影有感而发</title>
      <link>http://localhost:1313/post/2024/05/15/%E5%85%B3%E4%BA%8E%E6%91%84%E5%BD%B1%E6%9C%89%E6%84%9F%E8%80%8C%E5%8F%91/</link>
      <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/05/15/%E5%85%B3%E4%BA%8E%E6%91%84%E5%BD%B1%E6%9C%89%E6%84%9F%E8%80%8C%E5%8F%91/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;松下G85搭配松下1445镜头&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;首先，为什么选松下，松下是我老朋友了，作为家电厂，用过他家的台灯。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;PS:我的第一台相机其实是奥巴的，不过是一台数码相机，那时候拍照没有讲究想到什么拍什么，不需要构图，拍照只是为了留恋，而不是为了装逼。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;第一次买相机其实也不太懂，搜索了一些资料就开始上手了，买到了才开始学习，比如机械电子快门，防抖，曝光补偿，iso，超采，以上都很有意思，改善了之前对单反的固有想法。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Ps的Adobe camera raw 可以通过算法实现超采，和去噪点，是对M43传感器不大的一些弥补，但是我如果只处理一张图片，去噪点功能其实对观感而言比超采更好。 也可以通过DXO Photolab实现，但是DXO个人感觉没有ACR效果好。&lt;/li&gt;&#xA;&lt;li&gt;松下的G85可以实现DUAL2 防抖，但是是需要一定的硬件支持的，也就是镜头支持。 &lt;a href=&#34;https://forum.xitek.com/thread-1760716-1-1.html&#34;&gt;https://forum.xitek.com/thread-1760716-1-1.html&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://av.jpn.support.panasonic.com/support/global/cs/dsc/download/index.html&#34;&gt;https://av.jpn.support.panasonic.com/support/global/cs/dsc/download/index.html&lt;/a&gt; 很遗憾，我的1445只能实现镜头防抖，不能协同。不过通过稳定器开启之后对手持改善很大。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;我的客观需要其实不高，但是人嘛，总是在有限的预算里有无限的追求。开始越来越尝试记录自己的生活，这也是一种进步吧，或许只有对生活充满期望，才可以应对我要到哪里去这个问题？&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Day</title>
      <link>http://localhost:1313/post/2024/05/02/my-first-day/</link>
      <pubDate>Thu, 02 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/05/02/my-first-day/</guid>
      <description>&lt;p&gt;Hello world !!!&lt;/p&gt;</description>
    </item>
    <item>
      <title>GCore HK Basic vm</title>
      <link>http://localhost:1313/post/2024/03/23/gcore-hk-basic-vm/</link>
      <pubDate>Sat, 23 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/03/23/gcore-hk-basic-vm/</guid>
      <description>&lt;p&gt;Gcore作为老牌互联网提供商，早期用过他家的DNS和CDN，体验还是很稳定的，虽然现在我是一个Cloudflare的忠实免费玩家。 GCore的vps分为两种，Core和Edge，Core的物理资源更充沛，Edge更便宜 当然我们只是需要一台简单的服务器做Vlog和脚本服务器使用，所以还是使用Edge,Edge更便宜 Gcore宣称出口流量免费，但是实际上BasicVM的入口也是免费的。虽然Basic VM只有100Mbps的速度，但是实测短时间超过是没有问题的，不过大流量下，我估计CPU和内存都顶不住&amp;hellip;当然CDN还是上了Cloudflare家的免费计划，CloudFlare是真的中小开发者的最佳选择。&lt;/p&gt;&#xA;&lt;p&gt;Done&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gredge</title>
      <link>http://localhost:1313/post/2024/03/21/gredge/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/03/21/gredge/</guid>
      <description>&lt;p&gt;第一次体验了克系的游戏，虽然游戏剧情开始有点懵，但是之后跟着攻略走，打通了两个结局，还是看懂了一点。&lt;/p&gt;&#xA;&lt;p&gt;男主从海中捡到了书，但是也吸引出了海中的神明。妻子死后，男主后悔了，想要收回之前自己遗失的物品，通过书的力量献祭，复活自己的妻子，但此时，神明终于失去了最后的枷锁，灭世。&lt;/p&gt;&#xA;&lt;p&gt;若是，跟着守塔人的指引，向大海归还书，像多年前那样，大海只会收回男主的姓名。&lt;/p&gt;&#xA;&lt;p&gt;很简单的游戏，剧情流程也很短，不是很喜欢重复的工作，所以dlc没打，整体剧情开始很隐晦，后面很明朗。算是4.0的克系游戏。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vim</title>
      <link>http://localhost:1313/post/2024/03/20/vim/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/03/20/vim/</guid>
      <description>&lt;p&gt;Vim 简单配置&lt;/p&gt;&#xA;&lt;p&gt;sudo vim ~/.vimrc&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;set number   &amp;quot; 显示行号&#xA;set mouse=a  &amp;quot; 启用鼠标&#xA;set ruler    &amp;quot; 显示标尺（显示当前光标位置的行号、列号）&#xA;set cursorline  &amp;quot; 高亮显示当前行&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>世界，您好！</title>
      <link>http://localhost:1313/post/2024/03/20/%E4%B8%96%E7%95%8C%E6%82%A8%E5%A5%BD/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/2024/03/20/%E4%B8%96%E7%95%8C%E6%82%A8%E5%A5%BD/</guid>
      <description>&lt;p&gt;欢迎使用 WordPress。这是您的第一篇文章。编辑或删除它，然后开始写作吧！&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Test markdown&lt;/p&gt;&#xA;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/post/1/01/01/about-me/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/1/01/01/about-me/</guid>
      <description>&lt;p&gt;希望好奇心能驱使一个人走到八十岁。&lt;/p&gt;&#xA;&lt;p&gt;人总是在追求O(1)，我只想要(logn)。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
